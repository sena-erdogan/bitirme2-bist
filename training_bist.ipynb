{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5aacf261",
      "metadata": {
        "id": "5aacf261"
      },
      "outputs": [],
      "source": [
        "sample_df = df.sample(n=100000)\n",
        "\n",
        "# write the sample DataFrame to a CSV file\n",
        "sample_df.to_csv('100000twtunlabeled.csv', index=False)\n",
        "\n",
        "# confirm that the new file was created and contains the expected data\n",
        "new_df = pd.read_csv('100000twtunlabeled.csv')\n",
        "print(new_df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ad1a72b",
      "metadata": {
        "id": "8ad1a72b"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "01e5c3f6",
      "metadata": {
        "id": "01e5c3f6"
      },
      "outputs": [],
      "source": [
        "test_data = pd.read_csv('100000twtfinance.csv', sep=',')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fd5247b4",
      "metadata": {
        "id": "fd5247b4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "79b6689f",
      "metadata": {
        "id": "79b6689f"
      },
      "outputs": [],
      "source": [
        "test_data = pd.read_csv('100000twtnotfinance.csv', sep=',')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e85757ea",
      "metadata": {
        "id": "e85757ea"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "9f702c23",
      "metadata": {
        "id": "9f702c23",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cee8e33d-343a-4b1c-a3d2-8c2b7cb44668"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install --upgrade transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aZjn7drn30Dv",
        "outputId": "2c43696d-fc7c-4586-fabc-7ad02061b41c"
      },
      "id": "aZjn7drn30Dv",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.29.2-py3-none-any.whl (7.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m91.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
            "Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n",
            "  Downloading huggingface_hub-0.15.1-py3-none-any.whl (236 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.8/236.8 kB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m119.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.15.1 tokenizers-0.13.3 transformers-4.29.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install --upgrade accelerate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kEIxchlr30yc",
        "outputId": "104681c7-eb8e-41e1-e37d-54ea097aa2b5"
      },
      "id": "kEIxchlr30yc",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting accelerate\n",
            "  Downloading accelerate-0.19.0-py3-none-any.whl (219 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m219.1/219.1 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.0.1+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->accelerate) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->accelerate) (16.0.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->accelerate) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->accelerate) (1.3.0)\n",
            "Installing collected packages: accelerate\n",
            "Successfully installed accelerate-0.19.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "78e8266d",
      "metadata": {
        "id": "78e8266d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0797e6f2-2059-4165-8e25-2fc78edf9ffc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "file_path = '/content/drive/MyDrive/Colab Notebooks/tlg_labeled.pth'\n",
        "print(os.path.isfile(file_path))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d3aec2b3",
      "metadata": {
        "id": "d3aec2b3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2c2cffc-3daa-4930-8a2f-7841677dcfd0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.29.2-py3-none-any.whl (7.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m51.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
            "Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n",
            "  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m85.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.14.1 tokenizers-0.13.3 transformers-4.29.2\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ecf5bca",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ecf5bca",
        "outputId": "b984c112-495a-403e-d841-22cc84cbf1c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Windows-1252\n"
          ]
        }
      ],
      "source": [
        "import chardet\n",
        "\n",
        "# Read the CSV file as binary\n",
        "with open('5000_tlg_labeled.csv', 'rb') as f:\n",
        "    result = chardet.detect(f.read())\n",
        "\n",
        "# Print the detected encoding\n",
        "print(result['encoding'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "22b7cd20",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "22b7cd20",
        "outputId": "2e093716-a033-4f84-e83a-5a700b4f21df"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-d3d7d7be-944d-4458-82b8-cfcaf12703d3\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-d3d7d7be-944d-4458-82b8-cfcaf12703d3\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving 300_tlg_unlabeled.csv to 300_tlg_unlabeled.csv\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "\n",
        "\n",
        "uploaded = files.upload()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b246f297",
      "metadata": {
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b246f297",
        "outputId": "6836f0a1-baa7-4bae-eca2-329f5d3765b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at dbmdz/bert-base-turkish-cased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dbmdz/bert-base-turkish-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2, Step 1/450, Loss 0.9527\n",
            "Epoch 1/2, Step 11/450, Loss 1.3660\n",
            "Epoch 1/2, Step 21/450, Loss 1.3442\n",
            "Epoch 1/2, Step 31/450, Loss 0.6865\n",
            "Epoch 1/2, Step 41/450, Loss 1.3360\n",
            "Epoch 1/2, Step 51/450, Loss 1.0298\n",
            "Epoch 1/2, Step 61/450, Loss 1.2141\n",
            "Epoch 1/2, Step 71/450, Loss 1.2051\n",
            "Epoch 1/2, Step 81/450, Loss 1.2652\n",
            "Epoch 1/2, Step 91/450, Loss 0.7484\n",
            "Epoch 1/2, Step 101/450, Loss 0.9562\n",
            "Epoch 1/2, Step 111/450, Loss 0.9988\n",
            "Epoch 1/2, Step 121/450, Loss 1.0890\n",
            "Epoch 1/2, Step 131/450, Loss 0.6198\n",
            "Epoch 1/2, Step 141/450, Loss 0.6485\n",
            "Epoch 1/2, Step 151/450, Loss 0.5769\n",
            "Epoch 1/2, Step 161/450, Loss 1.5471\n",
            "Epoch 1/2, Step 171/450, Loss 1.2931\n",
            "Epoch 1/2, Step 181/450, Loss 1.0751\n",
            "Epoch 1/2, Step 191/450, Loss 0.5123\n",
            "Epoch 1/2, Step 201/450, Loss 0.7364\n",
            "Epoch 1/2, Step 211/450, Loss 1.3563\n",
            "Epoch 1/2, Step 221/450, Loss 0.2423\n",
            "Epoch 1/2, Step 231/450, Loss 0.3775\n",
            "Epoch 1/2, Step 241/450, Loss 1.2729\n",
            "Epoch 1/2, Step 251/450, Loss 0.8302\n",
            "Epoch 1/2, Step 261/450, Loss 0.8841\n",
            "Epoch 1/2, Step 271/450, Loss 0.3008\n",
            "Epoch 1/2, Step 281/450, Loss 1.2024\n",
            "Epoch 1/2, Step 291/450, Loss 0.6291\n",
            "Epoch 1/2, Step 301/450, Loss 2.0043\n",
            "Epoch 1/2, Step 311/450, Loss 0.5927\n",
            "Epoch 1/2, Step 321/450, Loss 0.2539\n",
            "Epoch 1/2, Step 331/450, Loss 1.3272\n",
            "Epoch 1/2, Step 341/450, Loss 0.1700\n",
            "Epoch 1/2, Step 351/450, Loss 0.3601\n",
            "Epoch 1/2, Step 361/450, Loss 1.4417\n",
            "Epoch 1/2, Step 371/450, Loss 0.2478\n",
            "Epoch 1/2, Step 381/450, Loss 0.3109\n",
            "Epoch 1/2, Step 391/450, Loss 0.1942\n",
            "Epoch 1/2, Step 401/450, Loss 1.6676\n",
            "Epoch 1/2, Step 411/450, Loss 1.0040\n",
            "Epoch 1/2, Step 421/450, Loss 0.2841\n",
            "Epoch 1/2, Step 431/450, Loss 2.7541\n",
            "Epoch 1/2, Step 441/450, Loss 0.8140\n",
            "Epoch 2/2, Step 1/450, Loss 0.2407\n",
            "Epoch 2/2, Step 11/450, Loss 0.5220\n",
            "Epoch 2/2, Step 21/450, Loss 0.1728\n",
            "Epoch 2/2, Step 31/450, Loss 1.0801\n",
            "Epoch 2/2, Step 41/450, Loss 1.5040\n",
            "Epoch 2/2, Step 51/450, Loss 0.2624\n",
            "Epoch 2/2, Step 61/450, Loss 0.2314\n",
            "Epoch 2/2, Step 71/450, Loss 0.0342\n",
            "Epoch 2/2, Step 81/450, Loss 0.1259\n",
            "Epoch 2/2, Step 91/450, Loss 0.0668\n",
            "Epoch 2/2, Step 101/450, Loss 0.1183\n",
            "Epoch 2/2, Step 111/450, Loss 0.1910\n",
            "Epoch 2/2, Step 121/450, Loss 0.0607\n",
            "Epoch 2/2, Step 131/450, Loss 0.2692\n",
            "Epoch 2/2, Step 141/450, Loss 2.1895\n",
            "Epoch 2/2, Step 151/450, Loss 0.0747\n",
            "Epoch 2/2, Step 161/450, Loss 0.0436\n",
            "Epoch 2/2, Step 171/450, Loss 0.0866\n",
            "Epoch 2/2, Step 181/450, Loss 0.5667\n",
            "Epoch 2/2, Step 191/450, Loss 0.1277\n",
            "Epoch 2/2, Step 201/450, Loss 0.2941\n",
            "Epoch 2/2, Step 211/450, Loss 0.4545\n",
            "Epoch 2/2, Step 221/450, Loss 1.3865\n",
            "Epoch 2/2, Step 231/450, Loss 0.2211\n",
            "Epoch 2/2, Step 241/450, Loss 1.7813\n",
            "Epoch 2/2, Step 251/450, Loss 0.0311\n",
            "Epoch 2/2, Step 261/450, Loss 0.1704\n",
            "Epoch 2/2, Step 271/450, Loss 2.8645\n",
            "Epoch 2/2, Step 281/450, Loss 2.2116\n",
            "Epoch 2/2, Step 291/450, Loss 0.0335\n",
            "Epoch 2/2, Step 301/450, Loss 0.0287\n",
            "Epoch 2/2, Step 311/450, Loss 0.3173\n",
            "Epoch 2/2, Step 321/450, Loss 0.0587\n",
            "Epoch 2/2, Step 331/450, Loss 0.1504\n",
            "Epoch 2/2, Step 341/450, Loss 0.0406\n",
            "Epoch 2/2, Step 351/450, Loss 2.7426\n",
            "Epoch 2/2, Step 361/450, Loss 1.7868\n",
            "Epoch 2/2, Step 371/450, Loss 0.5265\n",
            "Epoch 2/2, Step 381/450, Loss 0.5837\n",
            "Epoch 2/2, Step 391/450, Loss 0.3971\n",
            "Epoch 2/2, Step 401/450, Loss 2.2287\n",
            "Epoch 2/2, Step 411/450, Loss 2.6921\n",
            "Epoch 2/2, Step 421/450, Loss 0.8147\n",
            "Epoch 2/2, Step 431/450, Loss 0.0613\n",
            "Epoch 2/2, Step 441/450, Loss 2.0505\n",
            "Model saved to /content/drive/MyDrive/ColabNotebookModels/tlg_labeled.pth\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from torch.utils.data import DataLoader, RandomSampler, TensorDataset\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "\n",
        "# Load the labeled training set and create input tensors\n",
        "train_data = pd.read_csv('5000_tlg_labeled.csv', sep=';', encoding='Windows-1252')\n",
        "\n",
        "# Filter the training data to include only 500 rows for each label\n",
        "train_data = train_data.groupby('label').head(500)\n",
        "\n",
        "# Convert labels to integers\n",
        "label2int = {\"J\": 0, \"M\": 1, \"T\": 2}\n",
        "train_data['label'] = train_data['label'].map(label2int)\n",
        "\n",
        "# Get the training texts and labels as lists\n",
        "train_texts = train_data[\"content\"].tolist()\n",
        "train_labels = train_data[\"label\"].tolist()\n",
        "\n",
        "# Load the BERT tokenizer and tokenize the input texts\n",
        "tokenizer = BertTokenizer.from_pretrained('dbmdz/bert-base-turkish-cased')\n",
        "train_encodings = tokenizer(train_texts, truncation=True, padding=True, return_tensors=\"pt\")\n",
        "\n",
        "# Create a PyTorch dataset from the input encodings and labels\n",
        "train_dataset = TensorDataset(\n",
        "    train_encodings[\"input_ids\"],\n",
        "    train_encodings[\"attention_mask\"],\n",
        "    torch.tensor(train_labels),\n",
        ")\n",
        "\n",
        "# Load the BERT model and set the device\n",
        "model = BertForSequenceClassification.from_pretrained('dbmdz/bert-base-turkish-cased', num_labels=3)\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# Define the training hyperparameters\n",
        "batch_size = 2\n",
        "learning_rate = 1e-5\n",
        "num_epochs = 2\n",
        "warmup_steps = 0.1 * (len(train_dataset) // batch_size)\n",
        "total_steps = len(train_dataset) // batch_size * num_epochs\n",
        "num_warmup_steps = int(warmup_steps)\n",
        "num_training_steps = int(total_steps - num_warmup_steps)\n",
        "\n",
        "# Create a PyTorch DataLoader for the training set\n",
        "train_sampler = RandomSampler(train_dataset)\n",
        "train_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "# Create the optimizer and the scheduler\n",
        "optimizer = AdamW(model.parameters(), lr=learning_rate, eps=1e-8)\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=num_warmup_steps, num_training_steps=num_training_steps)\n",
        "\n",
        "# Define the loss function and the evaluation metric\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "metric_fn = torch.nn.functional.softmax\n",
        "\n",
        "# Training loop\n",
        "model.train()\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        batch_input_ids = batch[0].to(device)\n",
        "        batch_attention_mask = batch[1].to(device)\n",
        "        batch_labels = batch[2].to(device)\n",
        "\n",
        "        # Zero the gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(batch_input_ids, attention_mask=batch_attention_mask)\n",
        "        logits = outputs.logits\n",
        "\n",
        "        # Calculate loss\n",
        "        loss = loss_fn(logits, batch_labels)\n",
        "\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the gradients to prevent exploding gradients\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "\n",
        "        # Update the parameters\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate scheduler\n",
        "        scheduler.step()\n",
        "\n",
        "        # Print the loss for every 10th batch\n",
        "        if step % 10 == 0:\n",
        "            print(f\"Epoch {epoch+1}/{num_epochs}, Step {step+1}/{len(train_dataloader)}, Loss {loss.item():.4f}\")\n",
        "\n",
        "# Save the fine-tuned model\n",
        "model_path = \"/content/drive/MyDrive/ColabNotebookModels/tlg_labeled.pth\"\n",
        "\n",
        "if os.path.exists(model_path):\n",
        "    os.remove(model_path)\n",
        "\n",
        "torch.save(model.state_dict(), model_path)\n",
        "print(f\"Model saved to {model_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "51725c9d",
      "metadata": {
        "id": "51725c9d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41c157a4-6b2c-4362-fd4e-e94e316e48c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at dbmdz/bert-base-turkish-cased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dbmdz/bert-base-turkish-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2, Step 1/450, Loss 1.2477\n",
            "Epoch 1/2, Step 11/450, Loss 0.7871\n",
            "Epoch 1/2, Step 21/450, Loss 1.1926\n",
            "Epoch 1/2, Step 31/450, Loss 1.1322\n",
            "Epoch 1/2, Step 41/450, Loss 0.7180\n",
            "Epoch 1/2, Step 51/450, Loss 1.1442\n",
            "Epoch 1/2, Step 61/450, Loss 0.8694\n",
            "Epoch 1/2, Step 71/450, Loss 1.1660\n",
            "Epoch 1/2, Step 81/450, Loss 1.0880\n",
            "Epoch 1/2, Step 91/450, Loss 0.9828\n",
            "Epoch 1/2, Step 101/450, Loss 1.3570\n",
            "Epoch 1/2, Step 111/450, Loss 0.9899\n",
            "Epoch 1/2, Step 121/450, Loss 0.9856\n",
            "Epoch 1/2, Step 131/450, Loss 1.0387\n",
            "Epoch 1/2, Step 141/450, Loss 1.2086\n",
            "Epoch 1/2, Step 151/450, Loss 0.8434\n",
            "Epoch 1/2, Step 161/450, Loss 1.0908\n",
            "Epoch 1/2, Step 171/450, Loss 0.5340\n",
            "Epoch 1/2, Step 181/450, Loss 0.8464\n",
            "Epoch 1/2, Step 191/450, Loss 0.6039\n",
            "Epoch 1/2, Step 201/450, Loss 0.3896\n",
            "Epoch 1/2, Step 211/450, Loss 0.8284\n",
            "Epoch 1/2, Step 221/450, Loss 0.8413\n",
            "Epoch 1/2, Step 231/450, Loss 1.1744\n",
            "Epoch 1/2, Step 241/450, Loss 0.4425\n",
            "Epoch 1/2, Step 251/450, Loss 0.7877\n",
            "Epoch 1/2, Step 261/450, Loss 0.9778\n",
            "Epoch 1/2, Step 271/450, Loss 0.8926\n",
            "Epoch 1/2, Step 281/450, Loss 0.4874\n",
            "Epoch 1/2, Step 291/450, Loss 1.9768\n",
            "Epoch 1/2, Step 301/450, Loss 1.1355\n",
            "Epoch 1/2, Step 311/450, Loss 0.8905\n",
            "Epoch 1/2, Step 321/450, Loss 0.3119\n",
            "Epoch 1/2, Step 331/450, Loss 0.2441\n",
            "Epoch 1/2, Step 341/450, Loss 0.5830\n",
            "Epoch 1/2, Step 351/450, Loss 0.1730\n",
            "Epoch 1/2, Step 361/450, Loss 0.5768\n",
            "Epoch 1/2, Step 371/450, Loss 0.7625\n",
            "Epoch 1/2, Step 381/450, Loss 0.8458\n",
            "Epoch 1/2, Step 391/450, Loss 0.4829\n",
            "Epoch 1/2, Step 401/450, Loss 1.2691\n",
            "Epoch 1/2, Step 411/450, Loss 0.8671\n",
            "Epoch 1/2, Step 421/450, Loss 0.0827\n",
            "Epoch 1/2, Step 431/450, Loss 0.2902\n",
            "Epoch 1/2, Step 441/450, Loss 0.6130\n",
            "Epoch 2/2, Step 1/450, Loss 1.4717\n",
            "Epoch 2/2, Step 11/450, Loss 0.4577\n",
            "Epoch 2/2, Step 21/450, Loss 0.3014\n",
            "Epoch 2/2, Step 31/450, Loss 1.7200\n",
            "Epoch 2/2, Step 41/450, Loss 1.2602\n",
            "Epoch 2/2, Step 51/450, Loss 0.7701\n",
            "Epoch 2/2, Step 61/450, Loss 0.2894\n",
            "Epoch 2/2, Step 71/450, Loss 1.5057\n",
            "Epoch 2/2, Step 81/450, Loss 1.6565\n",
            "Epoch 2/2, Step 91/450, Loss 0.4611\n",
            "Epoch 2/2, Step 101/450, Loss 0.1445\n",
            "Epoch 2/2, Step 111/450, Loss 1.1679\n",
            "Epoch 2/2, Step 121/450, Loss 0.1407\n",
            "Epoch 2/2, Step 131/450, Loss 0.2354\n",
            "Epoch 2/2, Step 141/450, Loss 0.1651\n",
            "Epoch 2/2, Step 151/450, Loss 0.0571\n",
            "Epoch 2/2, Step 161/450, Loss 0.0825\n",
            "Epoch 2/2, Step 171/450, Loss 0.0428\n",
            "Epoch 2/2, Step 181/450, Loss 0.0402\n",
            "Epoch 2/2, Step 191/450, Loss 0.7505\n",
            "Epoch 2/2, Step 201/450, Loss 0.0224\n",
            "Epoch 2/2, Step 211/450, Loss 0.0335\n",
            "Epoch 2/2, Step 221/450, Loss 2.2504\n",
            "Epoch 2/2, Step 231/450, Loss 1.6840\n",
            "Epoch 2/2, Step 241/450, Loss 1.1967\n",
            "Epoch 2/2, Step 251/450, Loss 0.4968\n",
            "Epoch 2/2, Step 261/450, Loss 0.1874\n",
            "Epoch 2/2, Step 271/450, Loss 0.0662\n",
            "Epoch 2/2, Step 281/450, Loss 1.1083\n",
            "Epoch 2/2, Step 291/450, Loss 2.2774\n",
            "Epoch 2/2, Step 301/450, Loss 2.2833\n",
            "Epoch 2/2, Step 311/450, Loss 0.0451\n",
            "Epoch 2/2, Step 321/450, Loss 0.8710\n",
            "Epoch 2/2, Step 331/450, Loss 2.5572\n",
            "Epoch 2/2, Step 341/450, Loss 0.7127\n",
            "Epoch 2/2, Step 351/450, Loss 0.0319\n",
            "Epoch 2/2, Step 361/450, Loss 0.0944\n",
            "Epoch 2/2, Step 371/450, Loss 1.3535\n",
            "Epoch 2/2, Step 381/450, Loss 1.3640\n",
            "Epoch 2/2, Step 391/450, Loss 0.0739\n",
            "Epoch 2/2, Step 401/450, Loss 3.7901\n",
            "Epoch 2/2, Step 411/450, Loss 0.4113\n",
            "Epoch 2/2, Step 421/450, Loss 0.0388\n",
            "Epoch 2/2, Step 431/450, Loss 0.9024\n",
            "Epoch 2/2, Step 441/450, Loss 0.1191\n",
            "Iteration 1:\n",
            "Accuracy: 0.7956\n",
            "F1 Score: 0.7961\n",
            "Precision: 0.7974\n",
            "Recall: 0.7956\n",
            "Confusion Matrix:\n",
            "[[243  23  34]\n",
            " [ 15 240  44]\n",
            " [ 25  43 233]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.81      0.83       300\n",
            "           1       0.78      0.80      0.79       299\n",
            "           2       0.75      0.77      0.76       301\n",
            "\n",
            "    accuracy                           0.80       900\n",
            "   macro avg       0.80      0.80      0.80       900\n",
            "weighted avg       0.80      0.80      0.80       900\n",
            "\n",
            "Model saved to /content/drive/MyDrive/ColabNotebookModels/tlg_labeled.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at dbmdz/bert-base-turkish-cased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dbmdz/bert-base-turkish-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2, Step 1/450, Loss 1.2883\n",
            "Epoch 1/2, Step 11/450, Loss 1.0810\n",
            "Epoch 1/2, Step 21/450, Loss 1.5284\n",
            "Epoch 1/2, Step 31/450, Loss 0.9493\n",
            "Epoch 1/2, Step 41/450, Loss 1.1963\n",
            "Epoch 1/2, Step 51/450, Loss 1.1332\n",
            "Epoch 1/2, Step 61/450, Loss 1.0705\n",
            "Epoch 1/2, Step 71/450, Loss 0.8271\n",
            "Epoch 1/2, Step 81/450, Loss 0.8493\n",
            "Epoch 1/2, Step 91/450, Loss 0.9387\n",
            "Epoch 1/2, Step 101/450, Loss 1.2575\n",
            "Epoch 1/2, Step 111/450, Loss 0.9174\n",
            "Epoch 1/2, Step 121/450, Loss 0.7264\n",
            "Epoch 1/2, Step 131/450, Loss 1.0316\n",
            "Epoch 1/2, Step 141/450, Loss 0.7504\n",
            "Epoch 1/2, Step 151/450, Loss 0.9110\n",
            "Epoch 1/2, Step 161/450, Loss 0.7638\n",
            "Epoch 1/2, Step 171/450, Loss 0.9163\n",
            "Epoch 1/2, Step 181/450, Loss 0.7641\n",
            "Epoch 1/2, Step 191/450, Loss 1.3461\n",
            "Epoch 1/2, Step 201/450, Loss 1.3878\n",
            "Epoch 1/2, Step 211/450, Loss 1.4889\n",
            "Epoch 1/2, Step 221/450, Loss 0.3106\n",
            "Epoch 1/2, Step 231/450, Loss 1.3021\n",
            "Epoch 1/2, Step 241/450, Loss 1.3629\n",
            "Epoch 1/2, Step 251/450, Loss 1.1143\n",
            "Epoch 1/2, Step 261/450, Loss 0.5651\n",
            "Epoch 1/2, Step 271/450, Loss 0.6756\n",
            "Epoch 1/2, Step 281/450, Loss 1.0360\n",
            "Epoch 1/2, Step 291/450, Loss 0.7566\n",
            "Epoch 1/2, Step 301/450, Loss 1.1083\n",
            "Epoch 1/2, Step 311/450, Loss 0.4114\n",
            "Epoch 1/2, Step 321/450, Loss 0.4206\n",
            "Epoch 1/2, Step 331/450, Loss 0.8279\n",
            "Epoch 1/2, Step 341/450, Loss 0.5679\n",
            "Epoch 1/2, Step 351/450, Loss 2.1213\n",
            "Epoch 1/2, Step 361/450, Loss 0.2330\n",
            "Epoch 1/2, Step 371/450, Loss 1.3083\n",
            "Epoch 1/2, Step 381/450, Loss 0.3083\n",
            "Epoch 1/2, Step 391/450, Loss 0.1570\n",
            "Epoch 1/2, Step 401/450, Loss 1.3730\n",
            "Epoch 1/2, Step 411/450, Loss 1.3342\n",
            "Epoch 1/2, Step 421/450, Loss 0.0748\n",
            "Epoch 1/2, Step 431/450, Loss 1.5492\n",
            "Epoch 1/2, Step 441/450, Loss 0.1339\n",
            "Epoch 2/2, Step 1/450, Loss 0.4201\n",
            "Epoch 2/2, Step 11/450, Loss 0.0998\n",
            "Epoch 2/2, Step 21/450, Loss 0.6621\n",
            "Epoch 2/2, Step 31/450, Loss 0.0526\n",
            "Epoch 2/2, Step 41/450, Loss 0.0773\n",
            "Epoch 2/2, Step 51/450, Loss 1.1344\n",
            "Epoch 2/2, Step 61/450, Loss 0.0342\n",
            "Epoch 2/2, Step 71/450, Loss 0.7546\n",
            "Epoch 2/2, Step 81/450, Loss 0.0341\n",
            "Epoch 2/2, Step 91/450, Loss 0.8412\n",
            "Epoch 2/2, Step 101/450, Loss 0.7271\n",
            "Epoch 2/2, Step 111/450, Loss 0.0344\n",
            "Epoch 2/2, Step 121/450, Loss 2.1298\n",
            "Epoch 2/2, Step 131/450, Loss 0.0321\n",
            "Epoch 2/2, Step 141/450, Loss 0.0446\n",
            "Epoch 2/2, Step 151/450, Loss 0.0218\n",
            "Epoch 2/2, Step 161/450, Loss 1.3864\n",
            "Epoch 2/2, Step 171/450, Loss 0.0987\n",
            "Epoch 2/2, Step 181/450, Loss 0.0545\n",
            "Epoch 2/2, Step 191/450, Loss 0.0788\n",
            "Epoch 2/2, Step 201/450, Loss 0.2872\n",
            "Epoch 2/2, Step 211/450, Loss 1.6000\n",
            "Epoch 2/2, Step 221/450, Loss 0.0373\n",
            "Epoch 2/2, Step 231/450, Loss 0.0184\n",
            "Epoch 2/2, Step 241/450, Loss 0.1036\n",
            "Epoch 2/2, Step 251/450, Loss 2.6436\n",
            "Epoch 2/2, Step 261/450, Loss 3.3251\n",
            "Epoch 2/2, Step 271/450, Loss 0.1010\n",
            "Epoch 2/2, Step 281/450, Loss 2.3107\n",
            "Epoch 2/2, Step 291/450, Loss 3.2206\n",
            "Epoch 2/2, Step 301/450, Loss 2.4178\n",
            "Epoch 2/2, Step 311/450, Loss 0.1313\n",
            "Epoch 2/2, Step 321/450, Loss 0.0272\n",
            "Epoch 2/2, Step 331/450, Loss 0.3497\n",
            "Epoch 2/2, Step 341/450, Loss 0.6146\n",
            "Epoch 2/2, Step 351/450, Loss 0.0356\n",
            "Epoch 2/2, Step 361/450, Loss 0.0692\n",
            "Epoch 2/2, Step 371/450, Loss 0.8272\n",
            "Epoch 2/2, Step 381/450, Loss 0.0107\n",
            "Epoch 2/2, Step 391/450, Loss 0.0122\n",
            "Epoch 2/2, Step 401/450, Loss 2.4843\n",
            "Epoch 2/2, Step 411/450, Loss 2.6134\n",
            "Epoch 2/2, Step 421/450, Loss 0.9727\n",
            "Epoch 2/2, Step 431/450, Loss 0.0303\n",
            "Epoch 2/2, Step 441/450, Loss 1.2126\n",
            "Iteration 2:\n",
            "Accuracy: 0.8256\n",
            "F1 Score: 0.8249\n",
            "Precision: 0.8290\n",
            "Recall: 0.8256\n",
            "Confusion Matrix:\n",
            "[[271   8  21]\n",
            " [ 26 227  46]\n",
            " [ 34  22 245]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.90      0.86       300\n",
            "           1       0.88      0.76      0.82       299\n",
            "           2       0.79      0.81      0.80       301\n",
            "\n",
            "    accuracy                           0.83       900\n",
            "   macro avg       0.83      0.83      0.82       900\n",
            "weighted avg       0.83      0.83      0.82       900\n",
            "\n",
            "Model saved to /content/drive/MyDrive/ColabNotebookModels/tlg_labeled.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at dbmdz/bert-base-turkish-cased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dbmdz/bert-base-turkish-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2, Step 1/450, Loss 1.1682\n",
            "Epoch 1/2, Step 11/450, Loss 1.3990\n",
            "Epoch 1/2, Step 21/450, Loss 1.1430\n",
            "Epoch 1/2, Step 31/450, Loss 1.6449\n",
            "Epoch 1/2, Step 41/450, Loss 1.0382\n",
            "Epoch 1/2, Step 51/450, Loss 0.9200\n",
            "Epoch 1/2, Step 61/450, Loss 1.1947\n",
            "Epoch 1/2, Step 71/450, Loss 0.7641\n",
            "Epoch 1/2, Step 81/450, Loss 1.0639\n",
            "Epoch 1/2, Step 91/450, Loss 1.3055\n",
            "Epoch 1/2, Step 101/450, Loss 1.0860\n",
            "Epoch 1/2, Step 111/450, Loss 0.8838\n",
            "Epoch 1/2, Step 121/450, Loss 0.8907\n",
            "Epoch 1/2, Step 131/450, Loss 0.7868\n",
            "Epoch 1/2, Step 141/450, Loss 0.9901\n",
            "Epoch 1/2, Step 151/450, Loss 0.7894\n",
            "Epoch 1/2, Step 161/450, Loss 0.6920\n",
            "Epoch 1/2, Step 171/450, Loss 1.0520\n",
            "Epoch 1/2, Step 181/450, Loss 0.7689\n",
            "Epoch 1/2, Step 191/450, Loss 0.9385\n",
            "Epoch 1/2, Step 201/450, Loss 1.2912\n",
            "Epoch 1/2, Step 211/450, Loss 0.6366\n",
            "Epoch 1/2, Step 221/450, Loss 0.6430\n",
            "Epoch 1/2, Step 231/450, Loss 0.9653\n",
            "Epoch 1/2, Step 241/450, Loss 1.3406\n",
            "Epoch 1/2, Step 251/450, Loss 0.7574\n",
            "Epoch 1/2, Step 261/450, Loss 0.5314\n",
            "Epoch 1/2, Step 271/450, Loss 0.8892\n",
            "Epoch 1/2, Step 281/450, Loss 1.3055\n",
            "Epoch 1/2, Step 291/450, Loss 0.4369\n",
            "Epoch 1/2, Step 301/450, Loss 0.7496\n",
            "Epoch 1/2, Step 311/450, Loss 0.2333\n",
            "Epoch 1/2, Step 321/450, Loss 0.2059\n",
            "Epoch 1/2, Step 331/450, Loss 0.4135\n",
            "Epoch 1/2, Step 341/450, Loss 1.1658\n",
            "Epoch 1/2, Step 351/450, Loss 0.1705\n",
            "Epoch 1/2, Step 361/450, Loss 0.8794\n",
            "Epoch 1/2, Step 371/450, Loss 0.3678\n",
            "Epoch 1/2, Step 381/450, Loss 1.2041\n",
            "Epoch 1/2, Step 391/450, Loss 0.4585\n",
            "Epoch 1/2, Step 401/450, Loss 0.1333\n",
            "Epoch 1/2, Step 411/450, Loss 0.9962\n",
            "Epoch 1/2, Step 421/450, Loss 1.2732\n",
            "Epoch 1/2, Step 431/450, Loss 1.4421\n",
            "Epoch 1/2, Step 441/450, Loss 0.9038\n",
            "Epoch 2/2, Step 1/450, Loss 0.2954\n",
            "Epoch 2/2, Step 11/450, Loss 0.5017\n",
            "Epoch 2/2, Step 21/450, Loss 2.6461\n",
            "Epoch 2/2, Step 31/450, Loss 0.1423\n",
            "Epoch 2/2, Step 41/450, Loss 0.7634\n",
            "Epoch 2/2, Step 51/450, Loss 0.6271\n",
            "Epoch 2/2, Step 61/450, Loss 0.2399\n",
            "Epoch 2/2, Step 71/450, Loss 0.8928\n",
            "Epoch 2/2, Step 81/450, Loss 0.4186\n",
            "Epoch 2/2, Step 91/450, Loss 0.6099\n",
            "Epoch 2/2, Step 101/450, Loss 2.2839\n",
            "Epoch 2/2, Step 111/450, Loss 0.3764\n",
            "Epoch 2/2, Step 121/450, Loss 1.0986\n",
            "Epoch 2/2, Step 131/450, Loss 0.1657\n",
            "Epoch 2/2, Step 141/450, Loss 0.3445\n",
            "Epoch 2/2, Step 151/450, Loss 0.2204\n",
            "Epoch 2/2, Step 161/450, Loss 0.0659\n",
            "Epoch 2/2, Step 171/450, Loss 1.7897\n",
            "Epoch 2/2, Step 181/450, Loss 0.4864\n",
            "Epoch 2/2, Step 191/450, Loss 0.1047\n",
            "Epoch 2/2, Step 201/450, Loss 0.5961\n",
            "Epoch 2/2, Step 211/450, Loss 0.6044\n",
            "Epoch 2/2, Step 221/450, Loss 2.0127\n",
            "Epoch 2/2, Step 231/450, Loss 1.9301\n",
            "Epoch 2/2, Step 241/450, Loss 0.2322\n",
            "Epoch 2/2, Step 251/450, Loss 0.1372\n",
            "Epoch 2/2, Step 261/450, Loss 1.2157\n",
            "Epoch 2/2, Step 271/450, Loss 0.1305\n",
            "Epoch 2/2, Step 281/450, Loss 0.1082\n",
            "Epoch 2/2, Step 291/450, Loss 1.4793\n",
            "Epoch 2/2, Step 301/450, Loss 0.0470\n",
            "Epoch 2/2, Step 311/450, Loss 0.4436\n",
            "Epoch 2/2, Step 321/450, Loss 0.1009\n",
            "Epoch 2/2, Step 331/450, Loss 0.1219\n",
            "Epoch 2/2, Step 341/450, Loss 0.0491\n",
            "Epoch 2/2, Step 351/450, Loss 1.8961\n",
            "Epoch 2/2, Step 361/450, Loss 0.1787\n",
            "Epoch 2/2, Step 371/450, Loss 1.8240\n",
            "Epoch 2/2, Step 381/450, Loss 0.1027\n",
            "Epoch 2/2, Step 391/450, Loss 2.0221\n",
            "Epoch 2/2, Step 401/450, Loss 1.2021\n",
            "Epoch 2/2, Step 411/450, Loss 0.0345\n",
            "Epoch 2/2, Step 421/450, Loss 0.7689\n",
            "Epoch 2/2, Step 431/450, Loss 0.4500\n",
            "Epoch 2/2, Step 441/450, Loss 0.2214\n",
            "Iteration 3:\n",
            "Accuracy: 0.7867\n",
            "F1 Score: 0.7859\n",
            "Precision: 0.7861\n",
            "Recall: 0.7867\n",
            "Confusion Matrix:\n",
            "[[253  20  27]\n",
            " [ 24 239  36]\n",
            " [ 37  48 216]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.84      0.82       300\n",
            "           1       0.78      0.80      0.79       299\n",
            "           2       0.77      0.72      0.74       301\n",
            "\n",
            "    accuracy                           0.79       900\n",
            "   macro avg       0.79      0.79      0.79       900\n",
            "weighted avg       0.79      0.79      0.79       900\n",
            "\n",
            "Model saved to /content/drive/MyDrive/ColabNotebookModels/tlg_labeled.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at dbmdz/bert-base-turkish-cased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dbmdz/bert-base-turkish-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2, Step 1/450, Loss 1.2075\n",
            "Epoch 1/2, Step 11/450, Loss 1.4120\n",
            "Epoch 1/2, Step 21/450, Loss 1.0815\n",
            "Epoch 1/2, Step 31/450, Loss 1.5424\n",
            "Epoch 1/2, Step 41/450, Loss 1.4132\n",
            "Epoch 1/2, Step 51/450, Loss 0.6305\n",
            "Epoch 1/2, Step 61/450, Loss 1.6301\n",
            "Epoch 1/2, Step 71/450, Loss 1.2726\n",
            "Epoch 1/2, Step 81/450, Loss 1.0484\n",
            "Epoch 1/2, Step 91/450, Loss 0.9549\n",
            "Epoch 1/2, Step 101/450, Loss 0.9500\n",
            "Epoch 1/2, Step 111/450, Loss 1.0574\n",
            "Epoch 1/2, Step 121/450, Loss 0.9194\n",
            "Epoch 1/2, Step 131/450, Loss 1.4121\n",
            "Epoch 1/2, Step 141/450, Loss 0.8272\n",
            "Epoch 1/2, Step 151/450, Loss 1.2300\n",
            "Epoch 1/2, Step 161/450, Loss 0.8862\n",
            "Epoch 1/2, Step 171/450, Loss 0.6184\n",
            "Epoch 1/2, Step 181/450, Loss 0.4291\n",
            "Epoch 1/2, Step 191/450, Loss 1.3879\n",
            "Epoch 1/2, Step 201/450, Loss 1.1234\n",
            "Epoch 1/2, Step 211/450, Loss 1.9287\n",
            "Epoch 1/2, Step 221/450, Loss 0.9156\n",
            "Epoch 1/2, Step 231/450, Loss 0.5548\n",
            "Epoch 1/2, Step 241/450, Loss 1.0504\n",
            "Epoch 1/2, Step 251/450, Loss 0.6196\n",
            "Epoch 1/2, Step 261/450, Loss 1.4290\n",
            "Epoch 1/2, Step 271/450, Loss 0.6636\n",
            "Epoch 1/2, Step 281/450, Loss 1.0203\n",
            "Epoch 1/2, Step 291/450, Loss 0.3238\n",
            "Epoch 1/2, Step 301/450, Loss 0.1859\n",
            "Epoch 1/2, Step 311/450, Loss 0.9264\n",
            "Epoch 1/2, Step 321/450, Loss 2.0773\n",
            "Epoch 1/2, Step 331/450, Loss 1.2308\n",
            "Epoch 1/2, Step 341/450, Loss 0.4545\n",
            "Epoch 1/2, Step 351/450, Loss 0.7478\n",
            "Epoch 1/2, Step 361/450, Loss 0.3827\n",
            "Epoch 1/2, Step 371/450, Loss 0.8061\n",
            "Epoch 1/2, Step 381/450, Loss 0.5478\n",
            "Epoch 1/2, Step 391/450, Loss 0.1382\n",
            "Epoch 1/2, Step 401/450, Loss 0.3095\n",
            "Epoch 1/2, Step 411/450, Loss 0.9095\n",
            "Epoch 1/2, Step 421/450, Loss 0.2029\n",
            "Epoch 1/2, Step 431/450, Loss 0.7431\n",
            "Epoch 1/2, Step 441/450, Loss 0.9138\n",
            "Epoch 2/2, Step 1/450, Loss 0.2381\n",
            "Epoch 2/2, Step 11/450, Loss 0.1266\n",
            "Epoch 2/2, Step 21/450, Loss 0.1655\n",
            "Epoch 2/2, Step 31/450, Loss 0.0316\n",
            "Epoch 2/2, Step 41/450, Loss 0.8974\n",
            "Epoch 2/2, Step 51/450, Loss 0.7169\n",
            "Epoch 2/2, Step 61/450, Loss 1.1695\n",
            "Epoch 2/2, Step 71/450, Loss 1.6081\n",
            "Epoch 2/2, Step 81/450, Loss 1.7417\n",
            "Epoch 2/2, Step 91/450, Loss 1.5813\n",
            "Epoch 2/2, Step 101/450, Loss 0.1368\n",
            "Epoch 2/2, Step 111/450, Loss 0.2687\n",
            "Epoch 2/2, Step 121/450, Loss 0.0596\n",
            "Epoch 2/2, Step 131/450, Loss 0.5883\n",
            "Epoch 2/2, Step 141/450, Loss 0.0192\n",
            "Epoch 2/2, Step 151/450, Loss 1.7335\n",
            "Epoch 2/2, Step 161/450, Loss 0.0431\n",
            "Epoch 2/2, Step 171/450, Loss 1.3102\n",
            "Epoch 2/2, Step 181/450, Loss 0.0219\n",
            "Epoch 2/2, Step 191/450, Loss 0.3038\n",
            "Epoch 2/2, Step 201/450, Loss 0.4258\n",
            "Epoch 2/2, Step 211/450, Loss 0.0544\n",
            "Epoch 2/2, Step 221/450, Loss 0.8250\n",
            "Epoch 2/2, Step 231/450, Loss 1.2501\n",
            "Epoch 2/2, Step 241/450, Loss 0.0390\n",
            "Epoch 2/2, Step 251/450, Loss 2.0874\n",
            "Epoch 2/2, Step 261/450, Loss 2.1549\n",
            "Epoch 2/2, Step 271/450, Loss 1.1314\n",
            "Epoch 2/2, Step 281/450, Loss 0.0671\n",
            "Epoch 2/2, Step 291/450, Loss 0.1058\n",
            "Epoch 2/2, Step 301/450, Loss 2.1316\n",
            "Epoch 2/2, Step 311/450, Loss 2.0241\n",
            "Epoch 2/2, Step 321/450, Loss 0.6041\n",
            "Epoch 2/2, Step 331/450, Loss 2.4021\n",
            "Epoch 2/2, Step 341/450, Loss 0.1252\n",
            "Epoch 2/2, Step 351/450, Loss 0.2157\n",
            "Epoch 2/2, Step 361/450, Loss 2.5191\n",
            "Epoch 2/2, Step 371/450, Loss 1.4768\n",
            "Epoch 2/2, Step 381/450, Loss 3.0672\n",
            "Epoch 2/2, Step 391/450, Loss 0.1403\n",
            "Epoch 2/2, Step 401/450, Loss 0.0291\n",
            "Epoch 2/2, Step 411/450, Loss 0.6151\n",
            "Epoch 2/2, Step 421/450, Loss 0.0897\n",
            "Epoch 2/2, Step 431/450, Loss 0.0336\n",
            "Epoch 2/2, Step 441/450, Loss 2.4441\n",
            "Iteration 4:\n",
            "Accuracy: 0.7933\n",
            "F1 Score: 0.7927\n",
            "Precision: 0.8003\n",
            "Recall: 0.7933\n",
            "Confusion Matrix:\n",
            "[[262  12  26]\n",
            " [ 33 212  54]\n",
            " [ 43  18 240]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.87      0.82       300\n",
            "           1       0.88      0.71      0.78       299\n",
            "           2       0.75      0.80      0.77       301\n",
            "\n",
            "    accuracy                           0.79       900\n",
            "   macro avg       0.80      0.79      0.79       900\n",
            "weighted avg       0.80      0.79      0.79       900\n",
            "\n",
            "Model saved to /content/drive/MyDrive/ColabNotebookModels/tlg_labeled.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at dbmdz/bert-base-turkish-cased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dbmdz/bert-base-turkish-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2, Step 1/450, Loss 1.0202\n",
            "Epoch 1/2, Step 11/450, Loss 0.9458\n",
            "Epoch 1/2, Step 21/450, Loss 1.5173\n",
            "Epoch 1/2, Step 31/450, Loss 1.3321\n",
            "Epoch 1/2, Step 41/450, Loss 1.1664\n",
            "Epoch 1/2, Step 51/450, Loss 1.3726\n",
            "Epoch 1/2, Step 61/450, Loss 1.0700\n",
            "Epoch 1/2, Step 71/450, Loss 0.9924\n",
            "Epoch 1/2, Step 81/450, Loss 1.0529\n",
            "Epoch 1/2, Step 91/450, Loss 0.9359\n",
            "Epoch 1/2, Step 101/450, Loss 1.2826\n",
            "Epoch 1/2, Step 111/450, Loss 0.7261\n",
            "Epoch 1/2, Step 121/450, Loss 0.9627\n",
            "Epoch 1/2, Step 131/450, Loss 1.2056\n",
            "Epoch 1/2, Step 141/450, Loss 0.6503\n",
            "Epoch 1/2, Step 151/450, Loss 1.0256\n",
            "Epoch 1/2, Step 161/450, Loss 1.0969\n",
            "Epoch 1/2, Step 171/450, Loss 0.5540\n",
            "Epoch 1/2, Step 181/450, Loss 1.6916\n",
            "Epoch 1/2, Step 191/450, Loss 1.1236\n",
            "Epoch 1/2, Step 201/450, Loss 0.9314\n",
            "Epoch 1/2, Step 211/450, Loss 1.7279\n",
            "Epoch 1/2, Step 221/450, Loss 1.4731\n",
            "Epoch 1/2, Step 231/450, Loss 0.7381\n",
            "Epoch 1/2, Step 241/450, Loss 0.2104\n",
            "Epoch 1/2, Step 251/450, Loss 1.0145\n",
            "Epoch 1/2, Step 261/450, Loss 0.7249\n",
            "Epoch 1/2, Step 271/450, Loss 1.6211\n",
            "Epoch 1/2, Step 281/450, Loss 0.7988\n",
            "Epoch 1/2, Step 291/450, Loss 0.2015\n",
            "Epoch 1/2, Step 301/450, Loss 0.5519\n",
            "Epoch 1/2, Step 311/450, Loss 0.6010\n",
            "Epoch 1/2, Step 321/450, Loss 0.4099\n",
            "Epoch 1/2, Step 331/450, Loss 0.4484\n",
            "Epoch 1/2, Step 341/450, Loss 1.5811\n",
            "Epoch 1/2, Step 351/450, Loss 0.5585\n",
            "Epoch 1/2, Step 361/450, Loss 1.2149\n",
            "Epoch 1/2, Step 371/450, Loss 0.2458\n",
            "Epoch 1/2, Step 381/450, Loss 1.2278\n",
            "Epoch 1/2, Step 391/450, Loss 1.6086\n",
            "Epoch 1/2, Step 401/450, Loss 1.0533\n",
            "Epoch 1/2, Step 411/450, Loss 0.9058\n",
            "Epoch 1/2, Step 421/450, Loss 0.3342\n",
            "Epoch 1/2, Step 431/450, Loss 0.1046\n",
            "Epoch 1/2, Step 441/450, Loss 0.7708\n",
            "Epoch 2/2, Step 1/450, Loss 0.3739\n",
            "Epoch 2/2, Step 11/450, Loss 1.0487\n",
            "Epoch 2/2, Step 21/450, Loss 0.6412\n",
            "Epoch 2/2, Step 31/450, Loss 0.1963\n",
            "Epoch 2/2, Step 41/450, Loss 1.5450\n",
            "Epoch 2/2, Step 51/450, Loss 0.0891\n",
            "Epoch 2/2, Step 61/450, Loss 0.1061\n",
            "Epoch 2/2, Step 71/450, Loss 0.3963\n",
            "Epoch 2/2, Step 81/450, Loss 0.0428\n",
            "Epoch 2/2, Step 91/450, Loss 0.8777\n",
            "Epoch 2/2, Step 101/450, Loss 1.2985\n",
            "Epoch 2/2, Step 111/450, Loss 1.6069\n",
            "Epoch 2/2, Step 121/450, Loss 0.2137\n",
            "Epoch 2/2, Step 131/450, Loss 1.2484\n",
            "Epoch 2/2, Step 141/450, Loss 0.2804\n",
            "Epoch 2/2, Step 151/450, Loss 0.1966\n",
            "Epoch 2/2, Step 161/450, Loss 0.4885\n",
            "Epoch 2/2, Step 171/450, Loss 0.1879\n",
            "Epoch 2/2, Step 181/450, Loss 0.0726\n",
            "Epoch 2/2, Step 191/450, Loss 0.6155\n",
            "Epoch 2/2, Step 201/450, Loss 0.2864\n",
            "Epoch 2/2, Step 211/450, Loss 0.5633\n",
            "Epoch 2/2, Step 221/450, Loss 0.2158\n",
            "Epoch 2/2, Step 231/450, Loss 1.7193\n",
            "Epoch 2/2, Step 241/450, Loss 0.2931\n",
            "Epoch 2/2, Step 251/450, Loss 0.6300\n",
            "Epoch 2/2, Step 261/450, Loss 0.6437\n",
            "Epoch 2/2, Step 271/450, Loss 0.3271\n",
            "Epoch 2/2, Step 281/450, Loss 0.0293\n",
            "Epoch 2/2, Step 291/450, Loss 0.0708\n",
            "Epoch 2/2, Step 301/450, Loss 0.0400\n",
            "Epoch 2/2, Step 311/450, Loss 0.2436\n",
            "Epoch 2/2, Step 321/450, Loss 1.8688\n",
            "Epoch 2/2, Step 331/450, Loss 0.1647\n",
            "Epoch 2/2, Step 341/450, Loss 0.0254\n",
            "Epoch 2/2, Step 351/450, Loss 0.2211\n",
            "Epoch 2/2, Step 361/450, Loss 0.0279\n",
            "Epoch 2/2, Step 371/450, Loss 0.0988\n",
            "Epoch 2/2, Step 381/450, Loss 0.0875\n",
            "Epoch 2/2, Step 391/450, Loss 0.0152\n",
            "Epoch 2/2, Step 401/450, Loss 2.2481\n",
            "Epoch 2/2, Step 411/450, Loss 1.6323\n",
            "Epoch 2/2, Step 421/450, Loss 0.0515\n",
            "Epoch 2/2, Step 431/450, Loss 0.0785\n",
            "Epoch 2/2, Step 441/450, Loss 0.0335\n",
            "Iteration 5:\n",
            "Accuracy: 0.8000\n",
            "F1 Score: 0.7997\n",
            "Precision: 0.8078\n",
            "Recall: 0.8000\n",
            "Confusion Matrix:\n",
            "[[259  10  31]\n",
            " [ 29 213  57]\n",
            " [ 35  18 248]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.86      0.83       300\n",
            "           1       0.88      0.71      0.79       299\n",
            "           2       0.74      0.82      0.78       301\n",
            "\n",
            "    accuracy                           0.80       900\n",
            "   macro avg       0.81      0.80      0.80       900\n",
            "weighted avg       0.81      0.80      0.80       900\n",
            "\n",
            "Model saved to /content/drive/MyDrive/ColabNotebookModels/tlg_labeled.pth\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from torch.utils.data import DataLoader, RandomSampler, TensorDataset\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, classification_report\n",
        "\n",
        "# Load the labeled training set and create input tensors\n",
        "train_data = pd.read_csv('5000_tlg_labeled.csv', sep=';', encoding='Windows-1252')\n",
        "\n",
        "# Filter the training data to include only 500 rows for each label\n",
        "train_data = train_data.groupby('label').head(500)\n",
        "\n",
        "# Convert labels to integers\n",
        "label2int = {\"J\": 0, \"M\": 1, \"T\": 2}\n",
        "train_data['label'] = train_data['label'].map(label2int)\n",
        "\n",
        "# Get the training texts and labels as lists\n",
        "# # Usename\n",
        "train_texts = train_data[\"content\"].tolist()\n",
        "train_labels = train_data[\"label\"].tolist()\n",
        "\n",
        "# Load the BERT tokenizer and tokenize the input texts\n",
        "tokenizer = BertTokenizer.from_pretrained('dbmdz/bert-base-turkish-cased')\n",
        "train_encodings = tokenizer(train_texts, truncation=True, padding=True, return_tensors=\"pt\")\n",
        "\n",
        "# Create a PyTorch dataset from the input encodings and labels\n",
        "train_dataset = TensorDataset(\n",
        "    train_encodings[\"input_ids\"],\n",
        "    train_encodings[\"attention_mask\"],\n",
        "    torch.tensor(train_labels),\n",
        ")\n",
        "\n",
        "# Define the training hyperparameters\n",
        "batch_size = 2\n",
        "learning_rate = 1e-5\n",
        "num_epochs = 2\n",
        "warmup_steps = 0.1 * (len(train_dataset) // batch_size)\n",
        "total_steps = len(train_dataset) // batch_size * num_epochs\n",
        "num_warmup_steps = int(warmup_steps)\n",
        "num_training_steps = int(total_steps - num_warmup_steps)\n",
        "\n",
        "# Define evaluation metrics\n",
        "def evaluate(model, dataloader):\n",
        "    model.eval()\n",
        "    all_labels = []\n",
        "    all_preds = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            batch_input_ids = batch[0].to(device)\n",
        "            batch_attention_mask = batch[1].to(device)\n",
        "            batch_labels = batch[2].to(device)\n",
        "\n",
        "            outputs = model(batch_input_ids, attention_mask=batch_attention_mask)\n",
        "            logits = outputs.logits\n",
        "            preds = torch.argmax(logits, dim=1)\n",
        "\n",
        "            all_labels.extend(batch_labels.cpu().numpy())\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "\n",
        "    accuracy = accuracy_score(all_labels, all_preds)\n",
        "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
        "    precision = precision_score(all_labels, all_preds, average='weighted')\n",
        "    recall = recall_score(all_labels, all_preds, average='weighted')\n",
        "    confusion = confusion_matrix(all_labels, all_preds)\n",
        "    class_report = classification_report(all_labels, all_preds)\n",
        "\n",
        "    return accuracy, f1, precision, recall, confusion, class_report\n",
        "\n",
        "# Fine-tuning loop\n",
        "for iteration in range(5):  # Run for 5 iterations or adjust as needed\n",
        "    # Load the BERT model and set the device\n",
        "    model = BertForSequenceClassification.from_pretrained('dbmdz/bert-base-turkish-cased', num_labels=3)\n",
        "    device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "    model.to(device)\n",
        "\n",
        "    # Create a PyTorch DataLoader for the training set\n",
        "    train_sampler = RandomSampler(train_dataset)\n",
        "    train_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "    # Create the optimizer and the scheduler\n",
        "    optimizer = AdamW(model.parameters(), lr=learning_rate, eps=1e-8)\n",
        "    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=num_warmup_steps, num_training_steps=num_training_steps)\n",
        "\n",
        "    # Training loop\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        for step, batch in enumerate(train_dataloader):\n",
        "            batch_input_ids = batch[0].to(device)\n",
        "            batch_attention_mask = batch[1].to(device)\n",
        "            batch_labels = batch[2].to(device)\n",
        "\n",
        "            # Zero the gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(batch_input_ids, attention_mask=batch_attention_mask)\n",
        "            logits = outputs.logits\n",
        "\n",
        "            # Calculate loss\n",
        "            loss = loss_fn(logits, batch_labels)\n",
        "\n",
        "            # Backward pass\n",
        "            loss.backward()\n",
        "\n",
        "            # Clip the gradients to prevent exploding gradients\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "\n",
        "            # Update the parameters\n",
        "            optimizer.step()\n",
        "\n",
        "            # Update the learning rate scheduler\n",
        "            scheduler.step()\n",
        "\n",
        "            # Print the loss for every 10th batch\n",
        "            if step % 10 == 0:\n",
        "                print(f\"Epoch {epoch+1}/{num_epochs}, Step {step+1}/{len(train_dataloader)}, Loss {loss.item():.4f}\")\n",
        "\n",
        "    # Evaluate the model on the training set\n",
        "    accuracy, f1, precision, recall, confusion, class_report = evaluate(model, train_dataloader)\n",
        "    print(f\"Iteration {iteration+1}:\")\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"F1 Score: {f1:.4f}\")\n",
        "    print(f\"Precision: {precision:.4f}\")\n",
        "    print(f\"Recall: {recall:.4f}\")\n",
        "    print(\"Confusion Matrix:\")\n",
        "    print(confusion)\n",
        "    print(\"Classification Report:\")\n",
        "    print(class_report)\n",
        "\n",
        "    # Save the fine-tuned model\n",
        "    model_path = f\"/content/drive/MyDrive/ColabNotebookModels/tlg_labeled.pth\"\n",
        "\n",
        "    if os.path.exists(model_path):\n",
        "        os.remove(model_path)\n",
        "\n",
        "    torch.save(model.state_dict(), model_path)\n",
        "    print(f\"Model saved to {model_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "64483081",
      "metadata": {
        "scrolled": false,
        "id": "64483081",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "687528ce5f9643eb84a795ab7e005392",
            "d8f0cfeb34c44a468c150429b8e023c3",
            "23909718ef834e2292564f32431d10f1",
            "c1db9c843f2d4dbb8fc5feab7335f8cc",
            "daa52294c43b493d8f7119edf1e83bf3",
            "23ab5068b0274683a5883d0b6676bf93",
            "056cd416375943e88b1f8c78a2399664",
            "059d9aa3ac7540a7b487eee1917eb947",
            "778075f30d6b47e080f20f6d46869d2b",
            "19207e95730d47ab8b6cbf25c96e0f9c",
            "775e1406b9a44c0a9b8b9b5cc5d113db",
            "223149698a794b789fb1bba04e0515fa",
            "2449de21a2034b90a74007bdb5c84bf2",
            "915ddda5167848279eda36bcc13a5d3f",
            "f9acecc92fb24c219e5436954692f7c1",
            "1c823daf27e4412baf33a7f4d7d358c7",
            "f841b488a1aa4ea1b4ee6fe928de465f",
            "39599b451cb246c0a5ff240458d17c6a",
            "abe7010f42e046e893686503bac68659",
            "d019e5f173ac4bc291d8cf8509d0685c",
            "137b5a1605bc42eab7e5522b1c2f4a2b",
            "95e9e11836f34d03bad99730a64514a7",
            "61f077dc764b46f08228d7c9b87adf0a",
            "3d50a0b09a6d46f0b5bb04ddb449d713",
            "d0e119ec3f324ef8b8f3d17f518e61a9",
            "3dc68453879b40c18c37e7358a937d28",
            "c5e0caa1cc774888b480edfbc4d9fdb9",
            "6c5ffb2c329b45a2a195e081645626ad",
            "bc16acc4675541d49f4317c704bb74b5",
            "35841e629f284b9694870a33a5c748b9",
            "1029b2dc2ca040b59263b391c19ad735",
            "0d3f9a8727b447a49263205d7eba15b0",
            "3d31d53b120f48098ff12d1df8ba106b",
            "18ff91d71725447f9dd408ba2523243d",
            "6a667352749749859ab47d0d29332a2e",
            "cecae4a86587499f905e73782d7a3f3b",
            "9625534697ae4ea4bb7ffdfebdb8fd75",
            "fc6abb26ab3246a48e0918833572884d",
            "c87859f2c3bd4a79a91aba4356730438",
            "ce95c60603ec4d418486503342091c54",
            "6b6bf22ce01f4e1a9325218a728d6fad",
            "b8737d03e85a452691edbabdca2959ba",
            "c4c050456efa48b2bea28804b31a1028",
            "31eca2753ddd491594b85c757642a5c6"
          ]
        },
        "outputId": "70085a1c-6f3b-448d-d322-cbc18408bd67"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/385 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "687528ce5f9643eb84a795ab7e005392"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/445M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "223149698a794b789fb1bba04e0515fa"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at dbmdz/bert-base-turkish-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dbmdz/bert-base-turkish-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/251k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "61f077dc764b46f08228d7c9b87adf0a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/60.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "18ff91d71725447f9dd408ba2523243d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Labeled dataset saved to tlg_labeled_predictions.csv\n",
            "Saat ⏰ 11 .00 de Giriyoruz hep beraber Nakit 💴 hazırla\n",
            "0\n",
            "\n",
            "#EREGL 31.16 YÜRÜ BEEEE 😁 😁 💪 💪 💪 💪 💪\n",
            "1\n",
            "\n",
            "DOSTLAR BOMBA 💣 GİBİ BİR HİSSE SİZLER VERİYORUM ŞİMDİ HAZIR OLALIM.. 💪 💪 💪\n",
            "0\n",
            "\n",
            "#BIZIM 🌻 Tavan olmadı mı? Çabuk ol 👈 💴 💴 💴 💴\n",
            "1\n",
            "\n",
            "Arkadaşlar ... Zor bir gün oldu Endeksi hacmi çok düşüktü Gün içinde haber akışı biraz kötü olunca piyasa bozdu Sonra 15 dk endeksi iyi topladılar Bu gün 2000 puan üzeri ve (+) kapanış güzel Haftaya güzel olacak .... Sakin ve yolumuza devam İyi akşamlar\n",
            "2\n",
            "\n",
            "#fener de 31 e düşmicek bence\n",
            "1\n",
            "\n",
            "Gıdalar ve marketler gidecek ... 1/2 gün içinde bir anlaşma 🤝 olcak Rusya ufak bir gösteri 👈 Sakın unutma Bu sadece bir oyun 👈 Malını kaptırma\n",
            "2\n",
            "\n",
            "#fener 30 u alırsa tamamdır\n",
            "1\n",
            "\n",
            "BİST TOPARLANIR.. 💪 Durmak yok yola devam.. 💪\n",
            "0\n",
            "\n",
            "Bu gün.. Gıdalar çok önemli!!! #DARDL 🐟 Topla 👈 #BIZIM 🌻 Topla 👈 #MERKO 🍫 Topla 👈 Sonra #ULUUN 🌾 #ICBCT 🇨🇳 #DGGYO 🚢 Öncelik.... Dardanel ve bizim\n",
            "1\n",
            "\n",
            "#yyapı tavana 1 milyon TL kaldı Ben ne dedim size\n",
            "1\n",
            "\n",
            "#BIZIM 40 TL gidecek hazırlık yap 👈 💴\n",
            "1\n",
            "\n",
            "Sakin ve yolumuza devam\n",
            "0\n",
            "\n",
            "#ULUUN İçin atıp tutan bazı boş beyinler 🧠 var Sadece şunu demek istiyorum Allah akıl fikir versin Rusya 🇷🇺 ile Ukrayna 🇺🇦 arasında bir anlaşma 🤝 olmadığı sürece #ASELSAN gider 👈 #ULUUN gider 👈 #BIZIM gider 👈 #DARDL gider 👈 #MERKO gider 👈\n",
            "1\n",
            "\n",
            "Twittar aktif arkadaşlari görelim, orda da ayrı ekip kuruyorum.\n",
            "0\n",
            "\n",
            "#DGGYO 20 TL gidecek dedim Hala soran var yaaa Allah Allah 😊\n",
            "1\n",
            "\n",
            "MALIYET YAPMA YERİMİZ ARKADAŞLAR. DIP SEVIYELER BURALAR.\n",
            "0\n",
            "\n",
            "#DGGYO 🚢 Tavan olacak Çabuk ol 👈 Yarın ikinci tavan 👈 👈 👈\n",
            "1\n",
            "\n",
            "Bedava lot topla korkma\n",
            "2\n",
            "\n",
            "#ttkom 67 cent değerinde şu an, endekse göre olması gereken ölü fiyat dahi 74 cent\n",
            "2\n",
            "\n",
            "#YYAPI 0.86 SOL TARAFI SİZLER İÇİN DOLDURDUM.. 💪 💪 ✈️ ✈️ 💸 💸 İZLEYENLER MIPAZ GİBİ PİŞMAN OLACAK.. 😀 😀\n",
            "0\n",
            "\n",
            "#ERBOS YÜZDE 30 #DERIM YÜZDE 12 #TSPOR YÜZDE 24 #EUHOL YÜZDE 57 #YYAPI YÜZDE 10 #ERSU YÜZDE 8 #SILVER YÜZDE 3.5 #YGYO YÜZDE 2 #SANEL YÜZDE 20 #MIPAZ YÜZDE 12 TOPLAM YÜZDE 178 KAR GÖSTERDİM 💪 💪 💪 💪 💪 💪 💪 💪 💪 💪 💪 💪 💪\n",
            "1\n",
            "\n",
            "Amatör bir uzun vadeciysen Asla tek bir hisseyle yol alma, farklı sektörlerden farklı sepet yap, tüm birikimini tek seferde yatırma, sıkça al sat yapma,\n",
            "2\n",
            "\n",
            "DOLAR 18 İKEN PAHALI OLAN HERSEYİN DOLAR 13 İKEN YAKLASIK 2 KAT DAHA PAHALI OLMASI 😄\n",
            "0\n",
            "\n",
            "Sevgili Dostlar... Endeks biraz daha düşer ,maksimum 1760 a kadar düşecek ve akabinde tepki alıp kendini yukarı atacak ve 1900 bantları nı göreceğiz... Herkes terste kalacak ve...yukarı yön hareketini izleyecek 😉 Yurtdışı işlem yapan dostlar için ise DJI 33.500 puanı görecek ve yukarı hedefi izleyeceksiniz.. Hayırlı geceler\n",
            "2\n",
            "\n",
            "Dostlar.. Sayfa kuralları 1-) Hisselerde yapacağınız kârın en az yüzde %5'ini Mehmetçik Vakfına bağış ,diğer yüzde %5'ini çevrenizdeki fakir fukaraya yardım olarak yapmanızı istiyoruz. 2-) Sayımız çok fazla bu yüzden her tahtada tahtanın dengesini bozacak seviyede. 3-) Sayı fazlalığından dolayısıyla hisselere girişler portföy miktarınızın maksimum yüzde %10'u kadar olmalı 4-) Parasının toplam tutarının yüzde 10'undan fazla alan kişilerin riski tamamen kendisine aittir.. 5-) Bir hisse takibe almış iken aynı gün ve ya başka bir gün başka bir hisse daha takibimize alabiliriz..bu sayfada totalde maksimum aynı anda 3 hisse Takibimizde olur. 6-) 5. Kural dan dolayı bu yüzden her paylaşılan hisseye para miktarınızın maksimum yüzde %10' u ile girmeniz sizler için daha hayırlıdır,bu sayede ikinci hisseyide almak isterseniz diğer yüzde %10'u ile alabilme imkanınız olur. 7-) İkinci hisseyi takibe almamız birinci hisseden çıkış yapın demek değildir,her hisseden çıkış yapma zamanınız ister kâr ile ister zarar ile mutlaka sizlere söylenecektir. 8-) Hisse paylaşıldıktan sonra bizden satış talimatı gelene kadar istediğiniz yerden kâr almakta özgürsünüz. 9-) Burada paylaşılan hisseler bazen günlük bazen haftalık bazen aylık olabilir.. 10-) Hisselerde çıkış yerleri tarafımızca söylenecektir lakin hisseyi araştırıp beğenen var ise hissede kısa-orta vade de kalmaya devam edebilir,karar tamamen burada size aittir,Lakin çıkış yapın dediğimizde sizlerinde o dakika çıkış yapması ertesi gün hisseyi tekrardan alt seviyelerden almanız sizin için daha iyidir.(orta vade hissede kalmak isteyenler için ) Hissenin orta vade gidip gitmeyeceği bilgisi risk içerdiğinden verilmeyecektir,Hisseden çıkış yaptığınız gün hissenin son günü olabilir,Lakin genel itibariyle burada paylaşılan hisseler orta vadede daha yukarı gider. 11-)Burada paylaşılan hisseden bir kaç saat sonra aynı gün tavandan veya normal seviyeden kâr satışı sizlere yaptırabiliriz bu yüzden bildirimler açık olup hisse takibi buna göre yapılmalı..Hisseyi paylaşımdan bir iki saat sonra almak riski size aittir,Hissede tavandan kâr satışı yapın diyebiliriz bu yüzden tavandan hisseyi almak riski size aittir. 12-)Nakiti olmayanlar ve ertesi gün hisseye girmeyi düşünenler risk tamamen size aittir ,çünkü ertesi gün hisseden sizlere kâr satışı yaptırtabiliriz,ertesi gün hisseyi almanız riski size aittir. 13-) Paylaştığımız hisseler bazen bizim tahtasını yaptığımız hisseler bazen de piyasa hissesi olabilir bunun bilgisini önceden vermeyeceğiz çünkü sebep şudur bizim tahtamız olunca yüklü alışlar oluyor bunun önüne geçmek istiyoruz. 14-)Bazı durumlarda hissede stop olun diyebiliriz...Hissede ters bir durum gördüğümüzde aşağı doğru ani bir hareket var hisse örnek bir kaç günde yüzde 50 zarar etmektense yüzde %3-%5 gibi zararlar ile stop olalım diyebiliriz. 15-) Bir hissede stop olmak zarar etmek değildir daha fazla zararın önüne geçmektir ,Bir sonraki hissede bu zararı çıkartmak için elimizden geleni yaparız. 16-) Her hissede değil fakat bazı hisselerde duruma göre Maliyet çekin dediğimizde eğer hisseye giriş yaptıysan ilk aldığın lot kadar tekrar eklemeniz gerekecek ..bu şekilde hissede ki yeni maliyetiniz hesaplanacak 17-)Paylaşılan hisseler hergün aynı şekilde takip takip diye papağan gibi tekrar etmeyiz..Takibi biz kendimiz yapar zamanı geldiğinde çıkış yapın diye yazarız ve sizleri uygun yerden çıkartırız.. 18-)Bizler sizlere çok fazla para kazandırmak için gayret edeceğiz ve çalışacağız. 19-)Burada paylaşılan hisseler sizleri büyük zararlara uğratabilir bu yüzden hisseyi almanızı kesinlikle önermiyoruz. Not: Bu kurallar ara ara özelikle hisse paylaşımı yapılmadan önce sayfaya tekrar yazılır çünkü hatırlamanız için ve sayfaya yeni gelen üyelerimiz için .\n",
            "1\n",
            "\n",
            "Listem Önce dardanel Sonra Bizim Sonra Icbct Sonra Dggyo Sonra merko Korkmadan yolumuza devammmm\n",
            "0\n",
            "\n",
            "Piyasa toparlancak dedim mi toparlandı #yyapı mal kaptıranlar ağlayacak Yüzde 1-3 kâr ile hisse satılmaz.\n",
            "2\n",
            "\n",
            "#BIZIM 🌻 15.35 direnci kırdı Artık 17.80 var Toplayın 40 TL gidecek\n",
            "1\n",
            "\n",
            "0.67 kalkarsa başlar #ihyay\n",
            "2\n",
            "\n",
            "Son 1 aylık periyotta dolar bazlı en çok prim yapan hisseler. Bunları bilip, uçanın kaçanın peşinden koşmamak önemli.\n",
            "2\n",
            "\n",
            "#euhol toparladıktan sonra borsa yorumculuğunu bırakacağım. Şu an tek iş bu\n",
            "2\n",
            "\n",
            "İZLEYİN!\n",
            "0\n",
            "\n",
            "Türkiye'de #VESTL Nikel üreten bir şirket. Nikel fiyatları 4 günde %150 yükseldi. #Nikel batarya üretiminde kullanılan bir hammadde\n",
            "2\n",
            "\n",
            "Günaydın hayırlı sabahlar\n",
            "0\n",
            "\n",
            "MİLLET TAVANADAN TABAN TABAN YAPAR SİZLERE eksiden kağıdı verip tavana getiriyorum Sağda yolda beni kötülerler var Bu yüzden küçük yatırımcı kardeşlerimi kırgınım girdiğimiz hisselerde kar alıp ama beni kötülüyorlar çok ayıp bir şey yaptıklarım ortada\n",
            "2\n",
            "\n",
            "Agyo takipte !\n",
            "0\n",
            "\n",
            "Endeks durumuna göre hareket etmemiz gerekiyor. Her an endeks ters tepki vermeye başlar bayram geliyor bayramda nakit gecirmenizde fayda vardır.. Kagit uzerinde o kadar para bayramda bagli kalmaz 👍 Kar aldiginiz kagitlar var ise çebinize yakişır kar\n",
            "2\n",
            "\n",
            "#Eregl\n",
            "0\n",
            "\n",
            "9.64 tavan\n",
            "1\n",
            "\n",
            "#fener bereketli olsun 2 günde iyi para aldık bundan\n",
            "1\n",
            "\n",
            "Harika 💪 💪 💪 👈 👈 👈 ❤️ ❤️ ❤️ ❤️\n",
            "0\n",
            "\n",
            "Bu #yonga da #tavan tavan gidebilir cünkü hiç bişey yapmamış aylardır fiyatlama yok ve müthiç bir #bilanco var cok hızlı 45 50 lere gidebilir bugun tavanın durumuna göre belli olur.\n",
            "2\n",
            "\n",
            "Banka hisselerini ihmal eden hata eder. 1640 #Xbank yurt dışı piyasalarda bankalardaki alımlar kayda değer, algoritmaları tetikleyebilir, Bankalarda yükselişler gelebilir\n",
            "2\n",
            "\n",
            "hareket başlıcak gibi\n",
            "1\n",
            "\n",
            "3.16 direnci geçelim destek ver\n",
            "2\n",
            "\n",
            "Küçük YATIRIMCI kardeşlerime selam olsun\n",
            "0\n",
            "\n",
            "BİZLER PİYASANIN EN İYİSİYİZ VARSA KAZANDIRAN GRUP BİZDE TAKİP EDELİM SEN VE SENİN GİBİLERİ BAŞKA GRUPLARIN YÖNETİM EKİBİNDESİNİZ ÇEKEMİYORSUNUZ BİZLERİ O YÜZDEN GELİP BOYLE MESAJLAR ATIYORSUNUZ AMA MORALİMİZİ ASLA BOZMUYORUZ DURMAK YOK YOLA DEVAM 💪 💪 💪\n",
            "0\n",
            "\n",
            "#DGGYO 🚢 Haber düşecek 🤫\n",
            "0\n",
            "\n",
            "3.00 sonrası önümüz boş tavan kilit ve primli açılış gelecek 🧭\n",
            "2\n",
            "\n",
            "Herkese mutlu pazarlar ❤️\n",
            "0\n",
            "\n",
            "HAYIRLI KANDİLLER DİLERİM HERKESE, RABBIM DUALARIMIZI KABUL EYLESİN.\n",
            "0\n",
            "\n",
            "Günaydın Değerli Dostlar. Hayırlı Haftalar\n",
            "0\n",
            "\n",
            "Hayırlı akşamlar...\n",
            "0\n",
            "\n",
            "BORSAYA BAŞLADIĞINDAN BERİ HİÇ KAZANAMAMIŞ KİŞİLER VAR ARAMIZDA BİZLERİ TAKİP ETTİĞİNDEN DOLAYI KAZANMIŞ İLK KAZANDIĞI PARA İLE KAHVATIYI ISMARLADI KESESİNE BEREKET DİYORUM SABIRLI OLAN DOSTLAR SELAM OLSUN\n",
            "0\n",
            "\n",
            "Canli yayına gelelim\n",
            "0\n",
            "\n",
            "#ICBCT 🇨🇳 Tavan bekliyorum 🤫 Hacı çizer 👈 👈 👈\n",
            "1\n",
            "\n",
            "#ayen brüt perşembe son borsaya göre sağlam duruyor yarın bu tahta 17.50 lerde olur\n",
            "2\n",
            "\n",
            "#BIZIM Destek ver tahtayı çizelimmm Hayde 👈 💴 Toplaaa\n",
            "1\n",
            "\n",
            "#GLBMD Takipte\n",
            "0\n",
            "\n",
            "Endeks bir düzeltme yapacak Şişik BIST30 tahtalarından uzak durun\n",
            "2\n",
            "\n",
            "HIZLI TRADERLER ÖZELLİKLE TAKİPTE OLSUN 😄\n",
            "0\n",
            "\n",
            "#Odas düşüşü herkes izliyor Dün bilgisini verdik... Hikayesi en fazla yarına kadar demiştik..yani bugüne. Devre kesti 😉\n",
            "2\n",
            "\n",
            "Takibe geçin herkes bekliyoruz murat hoca markadır.. 💪\n",
            "0\n",
            "\n",
            "Buradan lot kaptıran ağlayacak\n",
            "2\n",
            "\n",
            "Devam 👈 Arkadaşlar biraz destek verin Tahta kopacak\n",
            "0\n",
            "\n",
            "Ben asla küçük yatırımcı dökmem onlarda kazansın isterim beni biliyorsunuz Elinde tutanlar için fırsat olacak\n",
            "2\n",
            "\n",
            "Günaydın dostlar... Güne biraz (-) Başlıyoruz\n",
            "0\n",
            "\n",
            "TEKRAR KURUYORUM\n",
            "0\n",
            "\n",
            "7,10 MALİYETLI AK YAT 5.10 K MALI VAR. SATISLAR ONUN SANIRIM. BURAYA DÖKÜLÜYOR ARKADAŞ.\n",
            "2\n",
            "\n",
            "TCMB faiz kararı pas bekliyorum Ama bir süpriz olur mu? Bu ülkede herşey olur\n",
            "2\n",
            "\n",
            "0.74 kaldıralım\n",
            "1\n",
            "\n",
            "3.03 👈 🐟 💪\n",
            "1\n",
            "\n",
            "Çağlar Başkan Taha Hamza'da canlı yayında ‼️ Link: https://instagram.com/sma_tahahamza?utm_medium=copy_link\n",
            "0\n",
            "\n",
            "#SILVR 6.36 Maşallah 🧿 💪 💪\n",
            "1\n",
            "\n",
            "#BIZIM Toplaaa Başlıyoruz 👈 💴\n",
            "1\n",
            "\n",
            "#BIZIM 🌻 Bu gün tavan bekliyorum dedim 14.85 % +9 yaptı Devammmmn 👈\n",
            "1\n",
            "\n",
            "#DARDL 🐟 Devam arkadaşlar.. Korkmadan yolumuza devam\n",
            "1\n",
            "\n",
            "#BIZIM 🌻 Tavan bekliyorum Topla 👈 👈 👈 👈\n",
            "1\n",
            "\n",
            "Bu fiyatlar bedava yukarı hareketimiz devam ediyor Satanın lotun u alıyorum\n",
            "2\n",
            "\n",
            "90 kalkıyor\n",
            "1\n",
            "\n",
            "YABANCI ŞİŞE SÜPÜRÜYOR.\n",
            "0\n",
            "\n",
            "BORSAYI ÇÖZEN ADAM pinned « #YYAPI BU GÜN TAVAN KAPATACAĞIZ »\n",
            "0\n",
            "\n",
            "Ayen sat.... Bizim topla....\n",
            "1\n",
            "\n",
            "#BIZIM 🌻 15.29 👈 Aç yolu 🌻\n",
            "1\n",
            "\n",
            "#BIST30 kar varsa ver dardanel yap Çabuk ol 👈 👈 👈\n",
            "1\n",
            "\n",
            "Ky anlıyorum giderken ustdat düşerken vay haline tahtacinin :)\n",
            "1\n",
            "\n",
            "Güzel olduk\n",
            "0\n",
            "\n",
            "#DGGYO 🚢 Devam 👈\n",
            "0\n",
            "\n",
            "GÖRÜYORSUNUZ BAŞKA GRUPLARI PAYLAŞIP ORDAN PARA ALIP MAL ÇAKIYOR SEDAT UYANIK SEDAT\n",
            "0\n",
            "\n",
            "2.02 ve 3 kalkarsa kopacak\n",
            "2\n",
            "\n",
            "#DARDL 🐟 Geliyor\n",
            "1\n",
            "\n",
            "Büyük gidecek hisse de takastan 150 bin tane mal satan A1 baskı yapma çabasında. Ama artık o malı kaptırdın devam!\n",
            "2\n",
            "\n",
            "BİZİM ZAMANIMIZ TEKRAR YAKLAŞIYOR DOSTLARIM.. SADECE ZAMANDAN KAYBETTİK GÜVENEN ARKADAŞLARIM ELLERİNDE TUTUYOR MALLARINI, DİĞERLERİ KENDİLERİNE YAZIK ETTİ..\n",
            "0\n",
            "\n",
            "Sakin ve yolumuza devam.... Malını kaptırma dedim... Bak .. Endeks 1994.18 % + 2 oldu Toparlanma devam edecek... Tam yol ileri\n",
            "2\n",
            "\n",
            "bu karar şu demek. negatif bir haber olduğu zaman , bazen de olmadan robotlar bunu kullanarak panik satışı yaptırabilecek.\n",
            "2\n",
            "\n",
            "Uluun tavan kapatabilir Bizim ve Dardanel yüklen 👈\n",
            "1\n",
            "\n",
            "#sanfm nin bilanco çok ışıltılı gelecek arkadaşlar. bi bakmısınız 35 den sıraya giriyorsunuz 😘 😘 😘 Az daha sabır 😘 😘 🔥 🔥 🚀 🚀\n",
            "1\n",
            "\n",
            "#YEŞİL KARDA DOSTLAR.. 💪 💪\n",
            "0\n",
            "\n",
            "#DGGYO 🚢 Cuma günü şov var 👈 👈 👈\n",
            "1\n",
            "\n",
            "#pınsu Son alıslarınızı yapabilirsiniz...\n",
            "1\n",
            "\n",
            "#fener süper ekmek verdi alana satana bereketli olsun 2 3 gün dür diyorum bu 30 u kıracak gidecek diye sabırlı olundumu olay çok basit\n",
            "2\n",
            "\n",
            "Devam arkadaşlar 👈 👈 👈\n",
            "0\n",
            "\n",
            "Günaydın Dostlar Yeni bir hafta yeni bir güne Başlıyoruz Bu gün yatay ve ufak + Başlıyoruz Endeks 2300 gidecek Tam yol ileri\n",
            "2\n",
            "\n",
            "#PEGYO SADECE DEDİKLERİMİ YAP GÜZEL PARALAR KAZAN 💸 💸 💸\n",
            "0\n",
            "\n",
            "#Petkm çok geride kalanlardan\n",
            "1\n",
            "\n",
            "BORSAYI ÇÖZEN ADAM pinned « MİLLET TAVANADAN TABAN TABAN YAPAR SİZLERE eksiden kağıdı verip tavana getiriyorum Sağda yolda beni kötülerler var Bu yüzden küçük yatırımcı kardeşlerimi kırgınım girdiğimiz hisselerde kar alıp ama beni kötülüyorlar çok ayıp bir şey yaptıklarım ortada »\n",
            "2\n",
            "\n",
            "MERHABA DOSTLAR.. 💪 💪 BU HAFTA BİZİM HAFTAMIZ OLACAKTIR.. ❤️ ❤️ ❤️\n",
            "0\n",
            "\n",
            "#ayen çok iyi olacak babuşlar bence yeni başlıyoruz. 😘 😘\n",
            "1\n",
            "\n",
            "KAR ALANLAR NAKİTTE BENİ BEKLESİNLER ARTIK TEK HİSSE VERECEĞİM SİZLERE DOSTLAR 💪 💪 💪 💪 💸 💸 💸 💸\n",
            "0\n",
            "\n",
            "ERSU HISSE GRUBU, 1 AYDIR ETMEDİĞİNİZ KÜFÜR HAKARET KALMADI, 4 LIRADAN 8 LIRAYA CEKTIGIM TAHTADA YASAKLARLA 1 AY OYALANDIK SADECE. 4 LİRADAN YINE ALMADINIZ AMA 15 TL DE ALIP YINE SALDIRACAKSINIZ. YAPACAK BSY YOK ERSU BENIM NAMUSUM ONURUM. TAHTAYI YINE ESKI YERINE GETİRECEM MALIYETE GELEN S.KTIRIP GIDEBILIR. IYI GECELER.\n",
            "0\n",
            "\n",
            "Canli yayına gelin 😊\n",
            "0\n",
            "\n",
            "#BIZIM 🌻 Tavan olursa 👈 #DARDL 🐟 Tavan deneye bilir\n",
            "1\n",
            "\n",
            "22:00 da canlı yayın olucak sadece 10-15 dk\n",
            "0\n",
            "\n",
            "#DGGYO 🚢 Üçüncü tavan bu gün topla 👈\n",
            "1\n",
            "\n",
            "Live stream started\n",
            "0\n",
            "\n",
            "Sakin ve yolumuza devam... Korkmadan... Bu gün 2000 puan üzeri kapanış yaparsa süper.. Toparlanma var ... Malını kaptırma Tam yol ileri\n",
            "2\n",
            "\n",
            "#VESTL KARDASINIZ SABIRLI OLALIM 😊 💪 #PNLSN KARDASINIZ SABIRLI OLALIM 😊 💪 #YESİL MALİYETTİNDE SORUN YOK 😉\n",
            "0\n",
            "\n",
            "1.94 dolsun sıra 1.95 de\n",
            "1\n",
            "\n",
            "#inves 30.40 ı alırsa sert başlar o rakama alarm kurdum\n",
            "2\n",
            "\n",
            "10.10 ❤️ 👈 🚢 🚢\n",
            "0\n",
            "\n",
            "#ygyo 0.72 tam dip dönüşü yapabileceği yerde\n",
            "1\n",
            "\n",
            "Takipde kal 👇 👇 https://instagram.com/borsakaranlikadam?igshid=YmMyMTA2M2Y=\n",
            "0\n",
            "\n",
            "Soru/cevap2\n",
            "0\n",
            "\n",
            "Arkadaşlar... Bu gün yatay ve ufak (+) açılış bekliyorum... Bu gün biraz yan tahtalar öne çıkacaktır... Sakin ve yolumuza devam .. Kısa listem... Aynı..... #DARDL #BIZIM #ICBCT #DGGYO Sonra merko\n",
            "1\n",
            "\n",
            "BORSAYI ÇÖZEN ADAM pinned « #DERIM TAKİBİME ALDIM »\n",
            "1\n",
            "\n",
            "BU SAVAŞ FAZLA SÜRMEZ BORSA GÜZEL OLACAK DOSTLAR.. 💪 💪\n",
            "0\n",
            "\n",
            "Haftalık takip listesi #Jants #Tskb #Trılc #Aselsan Yüzde 3 eksi stop ile takibe alıyoruz al sat tut kararları size aittir..Kar yeri sizlere aittir..\n",
            "2\n",
            "\n",
            "Sabah eksi 1 de olan endeks şu an + 1,25 te. Psikolojinizi yönetebilir, cesur ve sabırlı olursanız bu piyasada kaybetmeniz olanaksızdır\n",
            "2\n",
            "\n",
            "Aç yolu 👈\n",
            "0\n",
            "\n",
            "#BIZIM Bu gün tavan yapmak istiyorum Lütfen 🙏 biraz destek ver Her beraber\n",
            "1\n",
            "\n",
            "Çabuk ol 👈 👈 👈 🐟 🐟 🐟 🐟\n",
            "0\n",
            "\n",
            "Para 💴 kazan para 💴 🤫\n",
            "0\n",
            "\n",
            "Para 💴 kazan para\n",
            "0\n",
            "\n",
            "OSTIMDEYIM!\n",
            "0\n",
            "\n",
            "Günaydın efendim, 3.25 hedefimizle #agyo takibimiz devam etmekte fazlası olsun eksiği olmasın\n",
            "2\n",
            "\n",
            "Ramazan ayının habercisi üç ayların ilk Kandil gecesi olan Regaip Kandilimiz hayırlara vesile olsun.\n",
            "0\n",
            "\n",
            "T.me/ukrainenow Telegram Ukraine NOW Головне верифіковане інформаційне джерело про події в Україні The main verified source of official information about the current news in Ukraine Главный верифицированный информационный источник о событиях в Украине\n",
            "0\n",
            "\n",
            "Evet Trade edenler bittiğine göre başlıyoruz 🖋\n",
            "0\n",
            "\n",
            "Bu gün Gıdalar gidecek 👈\n",
            "0\n",
            "\n",
            "O YÜZDEN YAZMIYORUZ DİYE, GÖRMEYEN UNUTAN SİZLERİN GÖZÜNE SOKMUYORUZ DİYE HATA YAPTIĞIMIZI SÖYLÜYORLAR. BEN BUNU 10 SENE YAPMADIM, YAPMIYACAGIMDA. BİZİMLE OLAN BIZIMLE HAREKET EDEN SABREDEN PARA KAZANIR.. BİZ 10 TAVAN ÇEKİP 20 TABAN YAPAN TAHTA YAPMIYORUZ, ISTEYEN ISTEDIGI AN ALIP SATACAĞI PIYASAYA İZİN VEREN TAHTALARA İMZA ATIYORUZ. 10 TAVAN ÇEKEN ADAM 20 TABANA KENDİ KOYAR MALI UNUTMAYIN.\n",
            "0\n",
            "\n",
            "📍 Gmail : borsacaglar@gmail.com 📍 Grup : https://t.me/caglarborsa 📍 Kanal : https://t.me/borsanincaglari 📍 Twitter : https://twitter.com/CaglarBorsa\n",
            "0\n",
            "\n",
            "2 GÜN DAHA TOPLAMA 😉\n",
            "0\n",
            "\n",
            "3.29 🐟 💪\n",
            "1\n",
            "\n",
            "Bu hafta dggyo kaçırma 👈 👈 👈 👈 👈 👈 Bu hafta şov var 👈 👈 👈 👈\n",
            "1\n",
            "\n",
            "Son 4 kademe ❤️ ❤️ ❤️ 💪 💪 💪\n",
            "0\n",
            "\n",
            "#klmsn da dün bizi zorladı bakın bugüm kırıyor benim yazdığım bütün tahtaları mutlaka 2 3 gün zorlayın örnek #mndrs bakın artık hergün gidiyor ama çok zorladığında gitmiyor beklemek en iyisi mesela mndrs 2.50 ye geldiğinde ben malı verecem onun için bazı tahtalarda sessiz sessiz beklenmeli 😘\n",
            "2\n",
            "\n",
            "Arkadaşlar Endeks çok şişti Balon 🎈 çok şişti Bir düzeltme olacak Ama düzeltme şişik BIST30 TAHTALARINDA OLACAK O YÜZDEN.... #GIDALAR GİDECEK bak!!! #BIZIM 🌻 15.35 direnci geçti 15.89 gösterdi 17.80 bizi bekler toplayın 40 TL gidecek 👈 👈 ❤️ ❤️\n",
            "2\n",
            "\n",
            "KADROMUZ TAMAMLANDI DOSTLAR.. 😊 💪\n",
            "0\n",
            "\n",
            "ÇARŞAMBA GÜNÜ BEKLİYORUM\n",
            "0\n",
            "\n",
            "Asla kimseyi al sat yapıyor diye tahtada bilerek dökmem kul hakkına girmem, lakin al sat sizlere göre değil, istemeyerek olsa zarar edenleri görmemek mümkün değil. 21 altında maliyetiniz var ,eğer aldın ise ki zaten ilk verdiğimde aldınız videoda izledik...ya bekle yada kâr al durma tahtada\n",
            "2\n",
            "\n",
            "0.99 alış attım #mrgyo ama gelcek gibi durmuyor 1 i kaldıralım başlıyalım ne olacaksa olsun diyorum karsa kar zararsa zarar\n",
            "2\n",
            "\n",
            "Endeks düzeltme yapmaya başladı\n",
            "2\n",
            "\n",
            "BORSAYI ÇÖZEN ADAM pinned « https://t.me/Borsakraliyiz »\n",
            "0\n",
            "\n",
            "Sakin ve yolumuza devam edeceğiz korkmadan... Endeks 2300 gidecek\n",
            "2\n",
            "\n",
            "#dolar da haftaya 15 TL bekliyorum #endeks te tahminim yarın yada cuma aşaya sert yıkılır #viop ta 2250 üstünü beklemiyorum\n",
            "2\n",
            "\n",
            "Para 💴 kazan para 💴\n",
            "0\n",
            "\n",
            "Bide bu #angen i beğendim grafik çok güzel 26 27 ye kadar hızlı gideri var 25 i alırsa kopar\n",
            "2\n",
            "\n",
            "https://t.me/borsayibilenadam\n",
            "0\n",
            "\n",
            "#iheva tavan #ihyay ada gelebilirler 0.65 66 suan ihyay\n",
            "1\n",
            "\n",
            "Bu haber petrol tarafını yine hareketlendirdi. Petrolün yükselmesi bizim piyasaya satış getiriyor\n",
            "2\n",
            "\n",
            "Rusya Ukrayna sınırına birazdaha yaklaştı\n",
            "0\n",
            "\n",
            "#BIZIM 🌻 Önce 14.01 kırdı Sonra 14.62 kırdı Şimdi 15.35 kırmayı denedi 15.28 gösterdi Şimdi güç topluyor Bu hafta 15.35 kıracak ve sonra 17.85 var 17.85 geçtikten sonra çanak oluşacak 22.30 var Ben 40 TL dedim Ama bazı arkadaşlar dolar bazı grafikte 11 dolar 💵 dedi Bakalım şov ne kadar devam edecek Yakında güzel temettü haberi bekliyorum\n",
            "1\n",
            "\n",
            "Endeks güzel Başladı... 2103.99 % + 0.73 açtı 👈\n",
            "2\n",
            "\n",
            "#petkm bugün yarın 8 lira üstüne atmasını bekliyorum, sonra devam eder\n",
            "2\n",
            "\n",
            "Yeni takip hissesi #edip\n",
            "2\n",
            "\n",
            "PARA KAZANMAK PSİKOLOJİ İŞİ, SOLA VURAN VURANA. KARŞILAYAN BİRİ VAR ELBET 😄 PSİKOLOJİNİZİN BİTTİGİ YERDE YÜKSELİŞ BAŞLAR.\n",
            "0\n",
            "\n",
            "2.95 agyo kalk\n",
            "2\n",
            "\n",
            "GÜNAYDIN DOSTLAR.. ☕️ 😉\n",
            "0\n",
            "\n",
            "#DGGYO 🚢 Daha tavan olmadı mı? Çabuk ol Bu gün 2 tavan 👈\n",
            "1\n",
            "\n",
            "Yarın endeks yeşil kapatacak tüm piyasayı piyasa yapıcılar terste bırakacak desek ne işinize yarayacak ki değil mi ? Yada endeks yatayda yine kırmızı mı kapatacak ? Şu desteği kırar ise eksi kapatır kırmızı , lakin şu direnci kırar ise artı yeşil olur gibi piyasa ağzı ile mi konuşma mı istiyorsunuz ? Endeks konusunda sizler kendi bildiklerinizi uygulamaya devam edin ... Yarın yeşil mi yoksa kırmızı mı bilmiyorum:) Hepinizin gözlerinden öpüyorum Hayırlı geceler...\n",
            "2\n",
            "\n",
            "Live stream started\n",
            "0\n",
            "\n",
            "Savaşın devam etmesi emtia fiyatlarında yükselişi destekleyeceği için. havacılık sorunlu olur. yaptırımlar sebebi ile bankacılık endeksi baskı yemeye devam eder. bu durumda altın, demir çelik, doğalgaz petrol doğrudan borsa şirketlerini ilgilendiren emtiaları takip etmek gerekir. normalde bilanço satışı beklenen hisselerde yükselişin devam etmesinin temel nedeni bu. pandeminin etkisi azaldıkça düşüşe geçen emtia fiyatları savaş sesleri ile yeniden yükseltiliyor. Kişisel yorumum bu gerginliğin kısa sürede sona ermesi ve rüzgarın tersine dönmesi şeklinde. Olur olmaz bilemeyiz, eğer savaşın boyutu ilerlerse zaten borsa diye bir şey kalmaz. Ben buna ihtimal vermiyorum. Durum tersine dönerse, hisseler arasındaki değişime dikkat etmeli. Çünkü bazı hisseler bu durumda düzeltme sürecine girerken bazı hisseler yükseliş trendine girecektir yeniden.\n",
            "2\n",
            "\n",
            "Dostlar. Hayirli günler diliyorum. Nisan ayi için güzel bir çalişmamiz olacaktir. Endeksin biraz düzeltme yapmasını bekliyoruz. Her an her dakika hersey ola bilicek pozisyonlardayiz Buyuk ihtimal dostlar. Nisan ortalarına doğru saglam ve en dip noktalarda olan bir hisseye start vere biliriz. Ben detayları sizlere giriş yapmadan bilgilerini vericem grafik de atacağım şirket hakkında bilgileride sizlere sunucam Sağlam bir şirket ucuz kalmiş neredeyse bedava niyetine alacagimiz bir kagitdir. Oradaki dostlarımızda baya tersdeler maliyetleri onlarin yüksek iken biz düşük maliyet ile giriş yapmis olucaz.\n",
            "2\n",
            "\n",
            "74 yine kalkacak\n",
            "1\n",
            "\n",
            "Nakit 💴 hazırla 👈 👈 👈\n",
            "0\n",
            "\n",
            "Bu hafta güzel Marj aldık...yeni hissemiz Bayram hediyesi olsun size beklentimi ve detayları akşam yazacam...\n",
            "2\n",
            "\n",
            "#pegyo 1.10 kalkarsa #tavan olur\n",
            "1\n",
            "\n",
            "Para 💴 kazan para #ICBCT 🇨🇳 Bu gün gidecek 🤫\n",
            "1\n",
            "\n",
            "Endeks ... Bu gün yatay ve ufak + açılış bekliyorum 1960 üstünde tutunma çabası olacak bence 2000 puan üstünde kapanış süper olur\n",
            "2\n",
            "\n",
            "BÜTÜN HİSSELERİ SATIN NAKİTTE GEÇİN BENİ BEKLEYİN UFAK ZARARLAR TELAFİ EDİLİR\n",
            "0\n",
            "\n",
            "⚡ R. V.I.P | Ƥʀɪᴠᴀᴛᴇ ɢʀᴏᴜᴘ 🇹🇷 EKİBİMDE OLMAYAN; PORTFÖY 1M ÜZERİ OLAN ARKADAŞLAR DM DEN ULAŞSINLAR! T.me/mrpro7799 Telegram H E L P ŞİKAYETLERİNİZİ BİLDİRİN\n",
            "0\n",
            "\n",
            "GÜZEL KAR ALÇAKSINIZ DİYORUMMMMM DOSTLAR… 💪 💪 💪 💸 💸 💸 💸 💸 💸 💸 💸 💸 💸 💸 💸 💸 Para kazan Diyorummmmmmmm sizlere\n",
            "0\n",
            "\n",
            "sonra kopus\n",
            "0\n",
            "\n",
            "Piyasaya para girişi devam ediyor alıcılar satıcılar karşısın +200 milyon tl. ancak sağlıklı dengeli bir giriş değil bu. birkaç hisse özelinde endeks diri duruyor. çok yükselen ile çok düşük kalan arasında değişiklikler yapmak iyi olabilir.\n",
            "2\n",
            "\n",
            "Biraz piyasa durgun Bu gün böyle Yan tahtalar gidecek biraz..\n",
            "2\n",
            "\n",
            "#BIZIM 🌻 Gidecek 💪 💪 💪 💪\n",
            "0\n",
            "\n",
            "#BIZIM 🌻 16.32 olmuş 🤫 🤫 🤫\n",
            "1\n",
            "\n",
            "Arkadaşlar.... Bu gün endeksin hacmi çooooook düşük.. Saat 16.00 oldu endeksin hacmi 13 milyar olmadı Durgun bir gün Balinalar 🐋 mal topluyorlar malını kaptırma\n",
            "2\n",
            "\n",
            "Endeks genelinde alıcılar satıcılara karşı 150 milyon tl artıda, tablo iyi\n",
            "2\n",
            "\n",
            "#BIZIM Toplaaaa Bu gün tavan\n",
            "1\n",
            "\n",
            "trend yukarı döndü TTKOM da\n",
            "2\n",
            "\n",
            "#ICBCT 🇨🇳 Hareketi başladı 👈 Topla\n",
            "1\n",
            "\n",
            "kalktı\n",
            "1\n",
            "\n",
            "Yarın #DGGYO 🚢 #DARDL 🐟 #BIZIM 🌻 Yükleniyoruz 💪\n",
            "1\n",
            "\n",
            "#DGGYO tavan #BIZIM tavana gidiyoruz 👈\n",
            "1\n",
            "\n",
            "#DARDL 🐟 Kopacak 👈\n",
            "1\n",
            "\n",
            "Bankalar inanılmaz ucuz FK lara düşüyor , açıklanan karlarla , bugünkü en ciddi alıcıların ilk dört hisse tercihi #ykbnk #isctr #akbnk ve #garan\n",
            "2\n",
            "\n",
            "UFAK ZARARLARINIZ VARSA NAKİTTE GEÇİN DERİM.. BU HAFTA BİST ÇOK KÖTÜ OLACAK GİBİ DURUYOR.. 😡 😡\n",
            "0\n",
            "\n",
            "#vestl dün dikkat çektim yolculuğua devam, zaten listemizde de var\n",
            "1\n",
            "\n",
            "GEÇMİŞ OLSUN DOSTLAR, BUGÜN KAPANIŞ PLANIMIZDA DEĞİŞLİK OLDU PTESİ TELAFİSİNİ YAPARIZ. İYİ TATİLLER HERKESE. 👑 👑 👑 👑 👑\n",
            "0\n",
            "\n",
            "Günaydın hayırlı sabahlar...\n",
            "0\n",
            "\n",
            "BAKIN DOSTLAR BAŞKA GRUPLARDAN ALDIĞINIZ HİSSELERİ GELİP BANA SORMAYIN SİZLERE MAL ÇAKIYORLAR SONRADAN HOCAM YORUMLARMISINIZ BENİM VERDİĞİM HER HİSSE GİDİYOR.. BU ZAMANA KADAR YANILMADIM YANILMAMDA DOSTLAR.. 💪 💪 BEN VERDİĞİMDE AL BEKLE GÜZEL KAR ALIRSIN BENİM KAZANDIRDIKLARIMI HANGİ GRUP SİZLERE KAZANDIRMIŞ SÖYLERMİSİNİZ.. 😎\n",
            "0\n",
            "\n",
            "Avrupa piyasalarında sert satışlar olmasına rağmen çok iyi dayandık. Bunda aşağıda çok fazla yerimiz olmamasından kaynaklı bir durum var. Ancak iğne ipliği gibi robotlara bağlı bir piyasa olduğumuzu unutmayalım. Nakit boşluğu her zaman bırakalım\n",
            "2\n",
            "\n",
            "#EREGL 29.08maşallah 🧿\n",
            "1\n",
            "\n",
            "2200 endeks hedefi geldiği için, özellikle son 2 haftada aşırı prim yapan hisselerde dikkatli olmalı. Uzun vadecilere satın anlamında değildir bu, sadece yeni alımlar için acele etmemeli. Al satçılar ise, nispeten düşük kalan bankalar ile değişiklik yapabilirler. veya bir süre izlemede kalabilirler.\n",
            "2\n",
            "\n",
            "#isyat mükemmel oldu 3.15 maliyet ile isteyen kar alabilir ama ben devam edeceğim\n",
            "2\n",
            "\n",
            "#ttkom güçlü yabancı bir fon çıkışına karşılık yerli alım var. beklentisi olan bu tarz hisselerde yerli alımını daha çok önemsemeli. 9,40-9,50 ler alımda üzmez. uzun vade listemizde var. al sat için\n",
            "2\n",
            "\n",
            "tahtayı bulunca yazarım\n",
            "0\n",
            "\n",
            "5.50 üstüne atarsa kopar 💪\n",
            "2\n",
            "\n",
            "📍 ÇAĞLAR BAŞKAN ANLIK SESLİ SOHBETTE\n",
            "0\n",
            "\n",
            "Sevgili Dostlar... Cumanız mübarek olsun...\n",
            "0\n",
            "\n",
            "amk kağıt dipte kalkmıyo la sikim böyle borsayı la ank 0.78 kağıtmı kaldı ihlaslar harici tövbe tövbe\n",
            "2\n",
            "\n",
            "#DGGYO 🚢 Devam arkadaşlar devam 👈 Toplayın 👈 👈 👈\n",
            "1\n",
            "\n",
            "Avrupalı demir çelik hisselerinde emtialara bağlı sert düşüşler var. Demir çeliklerde olanlar dikkatli olmalı\n",
            "2\n",
            "\n",
            "Belirsizlik çok fazla. Özellikle Rusya swift yasağı tüm dünya banka endekslerini kötü etkiliyor. Kriz ortamında hisse alınır, satılmaz sabırlı olunur. Türk banka endeksinin avantajı fiyat kazancının çok cazip olması , dip fiyatta olması, toparlarken hızlı tepki verecek olmasıdır.\n",
            "2\n",
            "\n",
            "Günaydın yurt dışı piyasaların akşam ciddi toparlaması etkisiyle güne pozitif başlayacağız. Bilançolar gelmeye devam ediyor. GYO lar tarafında yeniden değerleme etkisi ile bilançolarda ciddi toparlama var , bu konudan geçen haftalarda söz etmiştim. Bankalar da gelecek. Burada dikkat edilmesi gereken, bilançoyu önceden fiyatlayan şirketlerde kar satışları olabilir, bu sebeple, sadece gelen bilanço değil mutlaka hisse grafiklerine de bakmanız gerektiği.\n",
            "2\n",
            "\n",
            "Sakin ve yolumuza devam Piyasa güzel olacak 2300 endeks gidecek\n",
            "2\n",
            "\n",
            "0.73 deki satıs biraz azalsın 0.73 ü ben kaldıracam\n",
            "2\n",
            "\n",
            "GÜNAYDIN ARKADAŞLAR. BEREKETLİ BİR GÜN DİLERİM.\n",
            "0\n",
            "\n",
            "#SILVR TAKİBİME ALDIM DOSTLAR.. 💪\n",
            "0\n",
            "\n",
            "Son cılız direncimiz 6.63 hafif direnç\n",
            "2\n",
            "\n",
            "Hayırlı sabahlar...\n",
            "0\n",
            "\n",
            "#YYAPI 0.84 TEN BİLDİRİMİ AÇIP ALANLAR ARKADAŞLAR.. 😂 😂\n",
            "0\n",
            "\n",
            "#BIZIM 17.00 den sonra kopuş olsun mu??? Toplaaaa\n",
            "1\n",
            "\n",
            "Şu anlık sadece 500 bin üstü\n",
            "0\n",
            "\n",
            "BORSAYI ÇÖZEN ADAM pinned « GÖNÜLDE Kİ HİSSEM HEP YEŞİL OLSUN DAİMA 💪 💪 ❤️ ❤️ »\n",
            "0\n",
            "\n",
            "Günaydın hayırlı sabahlar hayırlı cumalar BORSA ÇAĞLAR ailesi\n",
            "0\n",
            "\n",
            "Devam ediyoruz.. #Petkm 😉\n",
            "0\n",
            "\n",
            "Biz endeks yeşil kapatacak dedik eğer kapatmazlar ise böyle kapatırlar. Hangi hisse olduğunu iyi biliyorsunuz...T......;)\n",
            "2\n",
            "\n",
            "yurt dışı piyasalar fazlaca bozdu. Bize yansıyan korkusu 300 milyon tl para girişini nötre çekti. sakince gün sonunu görmeliyiz\n",
            "2\n",
            "\n",
            "#DGGYO 🚢 Çiz 💪 💪 💪\n",
            "1\n",
            "\n",
            "10 dakika sonra canlidayim toplanın\n",
            "0\n",
            "\n",
            "1.24 kalkması lazım\n",
            "2\n",
            "\n",
            "BORSAYI ÇÖZEN ADAM pinned « #YGYO TAKİBİME ALDIM.. 💪 💪 NOT:0.89 aldım »\n",
            "1\n",
            "\n",
            "23,50 geçti\n",
            "1\n",
            "\n",
            "#DARDL 🐟 3.11 Toplayın 👈 👈 👈\n",
            "1\n",
            "\n",
            "Güzel insanlar. Uzun süredir benim vip ekibime girmek isteyenler vardı ve, Uzun süredir sizin tahtanıza dahil olmak istiyorum diyenler vardı. Güzel bir tahta hazırlığım var. Kısa vadede 3 kat prim yapacağız. Bu tahta bittikten sonra hemen diğer tahtamız devreye girecek. Benimle uzun süre sürekli kazanç sağlamak sağlam bir aile ekibinde olmak isteyenler bize ulaşsınlar. 100 bin TL üstü kişiler mesaj atsın ve portföylerinizi bize atın ki oluşumu hızlı şekilde tamamlayalım. Limit koyuyorum çünkü sayı çok fazla arkadaslar. Herşey tamamlandığında 100 bin altı kişiler içinde oluşum yapacağım şimdilik onlar beklemede kalsınlar. Piyasa tavan tavan giden hisse nasıl olur herkes görecek. Bu süreçte bizimle olanlar kazanacak bizimle olmayanlar yok olup gidecektir,bu kadar açık ve net konuşuyorum. @Burakcozen Kullanıcı adına mesaj atabilirsiniz\n",
            "2\n",
            "\n",
            "#DARDL 🐟 3.25 👈 👈 👈 👈 Başlıyoruz 👈 👈 👈 👈\n",
            "1\n",
            "\n",
            "#Ekgyo geçen sefer dediğimde 2,32 idi, 2,50 geçer demiştim geçmişti. Bu defa 2,26 ya geriledi. Şimdi alacak olanlar biraz daha uzun vadeli alım yapabilirler. Bilanço sonrası fk düşüşü gelecek. çok cazip olacak. ama uzun vadeli al, çünkü piyasadaki yerli yatırımcının piyasayı karşılayacak gücü kalmadı. oyuncular geçici sert geri çekilmeler yapabilirler, büyük hareket öncesi tekrar bir silkeleme, sen aldığın malı bil, o mal ederine gelecek. unutma borsadan ucuz başka bir şey yok ülkede\n",
            "2\n",
            "\n",
            "#DARDL 🐟 15.00 den sonra yükleniyoruz Nakit 💴 hazırla 👈 🐟 💴 💪\n",
            "1\n",
            "\n",
            "#TTKOM bilançosu beklenti 5,2 milyar tl kar idi. Beklentinin bir tık üstünde 5,75 milyar tl kar açıkladı. uzun vade listemizde performansı düşük kalan hisselerimizden, ederini bulacaktır\n",
            "2\n",
            "\n",
            "Günaydın Dostlar... Hayırlı işler bol kazançlar...\n",
            "0\n",
            "\n",
            "#BIZIM Bu gün bilanço gelecek 👈 Bu gün tavan dener mi??? Toplaa 👈 💴\n",
            "1\n",
            "\n",
            "Erdoğan Bey... Konuşuyor... Rusya 🇷🇺 yı kınadı... Şimdi başka konulara girdi.. Şimdi .... Piyasayı alacaklar Endeks kötüyü fiyatladı... Artık piyasa gidecek Nakit varsa burdan fullle 💴 💴 💴 💴 💴 👈 👈 👈 👈 👈 👈\n",
            "2\n",
            "\n",
            "Ramazan ayı geldi Gıdalar Marketler Un fabrika Gidecek\n",
            "0\n",
            "\n",
            "İlk 5 yazdım Onun dışında ASELSAN / uluun gibi gibi devam\n",
            "0\n",
            "\n",
            "#DARDL Topla 👈 💴\n",
            "1\n",
            "\n",
            "bu tahta #krstl gibi olacak ama önce buralardan iyi mal toplıcaklar. #mndrs\n",
            "1\n",
            "\n",
            "91 kalkarsa #tavan arkadaşlar ben size diyim\n",
            "1\n",
            "\n",
            "0.78 kalkacak #ieyho\n",
            "1\n",
            "\n",
            "Endeks 2058 direnci geçti ... Şimdi tam yol ileri 2102 önemli direnç yeri bizi bekler\n",
            "2\n",
            "\n",
            "#ULUUN 🌾 Dün ufak bir düzeltme yaptı Patron 10 TL kadar hisse geri alımı yapacak Topla 👈\n",
            "1\n",
            "\n",
            "akdenizde #petrol ile ilgili çok büyük bir haber geleceği konusuluyor. bizide ısrarla vermemeleri kaç gündür büyük ihtimal sebebi bu haberin falan geleceğinden\n",
            "2\n",
            "\n",
            "#ICBCT Topla 👈 💴\n",
            "1\n",
            "\n",
            "#TSKB 1.66 VERDİK ŞUAN 1.71 OLDU 💪 💪 💪\n",
            "1\n",
            "\n",
            "#Petkm Nasıl Arkadaşlar güzelmi 🤑\n",
            "1\n",
            "\n",
            "Önemli bir direnç noktasından 2. Kapanışı yaptım. 😉 Satanın malını alırım sorun yok\n",
            "2\n",
            "\n",
            "MÜZAKERE GELİYOR. HAFTAYA RALLİ DEDİM DÜN!\n",
            "0\n",
            "\n",
            "#kozaa 20 liranın altı ucuzdur yine söylüyorum\n",
            "1\n",
            "\n",
            "17.00 den sonra piyasa iyi olacak dedim mi???\n",
            "2\n",
            "\n",
            "#BIZIM 1/4 yapacak 10.80 den başladı.. 40 TL üstüne atacak Süper haberler gelecek\n",
            "1\n",
            "\n",
            "Arkamdan akşama kadar konuşan insan müsveddelerinide seviyorum be. Bu devirde günahlarımı taşıyacak beygir zor bulunur. Biz bu açıdan bakalım 😬 😬 Günaydın hayırlı sabahlar hayırlı cumalar BORSA ÇAĞLAR ailesi\n",
            "0\n",
            "\n",
            "Gıdalar gidecek Marketler gidecek Un fabrikaları çok gidecek Savun sanayi çok gidecek Ben ne dersem o olacak Birde Rusların 🇷🇺 parası 💴 💴 💴 💴 💴 Bizim borsamıza girecek\n",
            "2\n",
            "\n",
            "Ramazan ayının habercisi, bolluk ve bereketi simgeleyen Berat Kandili’nin tüm Müslüman alemine hayırlı olmasını dilerim.\n",
            "0\n",
            "\n",
            "#DARDL 🐟 Topla bu gün Başlıyoruz\n",
            "1\n",
            "\n",
            "#DARDL Kopacak 🤫\n",
            "1\n",
            "\n",
            "Şişik BIST30 tahtalarında kâr cebe yap Endeks düzeltme yapacak BIST30 tahtaları geri gelecek Yan tahtalar ve spekler gidecek\n",
            "2\n",
            "\n",
            "4 LIRADAN 1/2 AYDA %100 YUKARI TAŞIDIĞIM VE MALIMI TUTTUGUM, 900 BIN LOT BANKOF SATISIYLA %2 EKSI KAPANIŞ YAPAN HİSSEDE, NE ANA BIRAKTINIZ NE SULALE.\n",
            "2\n",
            "\n",
            "Çabuk ol.... Para 💴 kazan tavan bekliyorum\n",
            "0\n",
            "\n",
            "Bu gün endeks iyi yol aldı BIST30 tahtalarında balinalar 🐋 top çevirdi Daha önce söyledim Panik yapma Malını kaptırma Endeks güzel olacak dedim 2007 direnci geçtik Artık 2058 bizi bekler sonra 2152 ve final 2300 konuşuruz Ben ne dersem o olacak Yarın yan tahtalar kopacak İyi akşamlar\n",
            "2\n",
            "\n",
            "Live stream started\n",
            "0\n",
            "\n",
            "Altın ve Dolar piyasa çok merak ediyormuş sizde ediyor musunuz?\n",
            "2\n",
            "\n",
            "BORSAYI ÇÖZEN ADAM pinned « #EUHOL BÖYLE GÜZEL Mİ DOSTLAR ✈️ ✈️ ✈️ 😊 😊 »\n",
            "0\n",
            "\n",
            "BU ŞEKİLDE YAPALIM ELİNDE HİSSE YOKSA İSE DAHİL BİR KÜÇÜK YATIRIMCI OLARAK YAPMAK ZORUNDASIN YOKSA BU TUR ADAMLAR YÜZÜNDEN KAYBETME ZORUNDA KALIRSIN SÜREKLİ.. BİZLERİ ÇEKEMEYENLER BUNLAR DOSTLAR..\n",
            "0\n",
            "\n",
            "Soru ve destek için 👇 👇 @Efetoglu\n",
            "0\n",
            "\n",
            "#BIZIM Bu sene 40 TL olacak Sözzzzz Hazırlık yap\n",
            "1\n",
            "\n",
            "Günaydın, güne hafif pozitif açılışla başlayacağız. Bugün merkez bankası faiz kararı var. Beklenti değişiklik olmaması yönünde, dolayısı ile kur ve endeks üzerinde etkisi olmayacaktır. Bugünlerde piyasa hareket verecek olan Garanti bankası kararı olabilir.\n",
            "2\n",
            "\n",
            "BORSAYI ÇÖZEN ADAM PARA SAYMA MAKİNASINI SİPARİŞ VERDİN DEMİŞTİ 💣\n",
            "0\n",
            "\n",
            "Günaydın Dostlar ... Hayırlı İşler Bol kazançlar\n",
            "0\n",
            "\n",
            "cart diye #tavan diyorum #grnyo\n",
            "1\n",
            "\n",
            "#DARDL 🐟 5 TL üzeri kısada sonra 10 TL yolculuk Yarın balık 🐟 günü Yarın dardanel tavan yapalım herkes destek versin\n",
            "1\n",
            "\n",
            "LÜTFEN DEFALARCA OKUYUN!\n",
            "0\n",
            "\n",
            "#PEGYO SATMIYACAĞIM.. 💪 💪 💸 💸\n",
            "1\n",
            "\n",
            "Bu sayfa sahte taklit bir sayfadır. Burası haricinde yazılan hiçbir şeye itimat etmeyin dostlar. Adıma açılmış çokça sayfa var. Benim hesabım sadece burasıdır\n",
            "0\n",
            "\n",
            "akşam #gozde nin bilancosu geliyormuş çok iyi bekleniyor.\n",
            "2\n",
            "\n",
            "Bugün yarın #rusya girebilir #altın ın tekniği yukarı kırıyor yarında cuma altın 1900 ü geçerse bilinki rusya gireceksin\n",
            "2\n",
            "\n",
            "#Thyao 26 yı geçti sabah alınır dediğim yer 24,30 idi üzerine neredeyse 2 lira koydu, al satçılar için yüzde 8 getiri demektir. bu.\n",
            "2\n",
            "\n",
            "#DGGYO 🚢 Dün tavan oldu söyledim ama Bu gün de tavan olacak Yarın da tavan 👈\n",
            "1\n",
            "\n",
            "Belki ben gelirim 😄\n",
            "0\n",
            "\n",
            "MIPAZ YÜZDE 35 kar Maşallah 🧿\n",
            "0\n",
            "\n",
            "KIMMR 😉 BEDELSİZ İHTİMALİ ÇOK YÜKSEK! ELİMDEKI 3 KAGITTAN BİRİ ❤️\n",
            "0\n",
            "\n",
            "#ICBCT Hazırlık yap\n",
            "1\n",
            "\n",
            "#isyat 3.52 lere geldi 3.15 den beri ısrarcıyım boşuna demedik buradan biraz kar satışları olabilir haberiniz olsun\n",
            "2\n",
            "\n",
            "Merhaba dostlar Tahtaya devam #Tcell\n",
            "1\n",
            "\n",
            "HERKESE MERHABA DOSTLAR.. 💪\n",
            "0\n",
            "\n",
            "Orta vade portföyümde #kozaa bulunduracağım 33,20 ile takibimde.\n",
            "2\n",
            "\n",
            "Peki zarar eden kim .. 200 Luk araca 500 veren bireysel kişi şu anda ağlıyor mu ağlıyor çok daha ağlayacak ...çok uyardık buradan...o araç elinde kaldı ..ne dedik kalacak dedik...insanlar şu anda araç almıyorlar...akıllı insan almaz.\n",
            "2\n",
            "\n",
            "#DARDL 🐟 3.27 👈 Gösterdi 3.30 tavan 🤫 Yarın otoban 🛣\n",
            "1\n",
            "\n",
            "Bu ayın son haftasından itibaren Kur Korumalı mevduat hesaplarının dönüşüm haftası, emtia fiyatları yüksek seyretmeye devam ederse, parası reel olarak eriyen insanlar kur korumalı mevduattan kısmen çıkış yapabilir. Bu durumda gayrimenkul, altın, hisse senedi gibi varlıklar ön plana çıkabilir. bu konuda daha cazip düzenlemelere ihtiyaç var. Savaşın seyri çok önemli\n",
            "2\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from transformers import BertForSequenceClassification, BertTokenizer\n",
        "import torch\n",
        "import pandas as pd\n",
        "\n",
        "# Load the retrained model\n",
        "model = BertForSequenceClassification.from_pretrained('dbmdz/bert-base-turkish-cased', num_labels=3)\n",
        "model.load_state_dict(torch.load(\"/content/drive/MyDrive/ColabNotebookModels/tlg_labeled.pth\"))\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# Load the test set and create input tensors\n",
        "# Assume that the test data is in CSV format with two columns: message_detail and username\n",
        "test_data = pd.read_csv('300_tlg_unlabeled.csv', sep=',')\n",
        "test_texts = test_data[\"content\"].tolist()\n",
        "\n",
        "# Load the BERT tokenizer and tokenize the input texts\n",
        "tokenizer = BertTokenizer.from_pretrained('dbmdz/bert-base-turkish-cased')\n",
        "\n",
        "test_encodings = tokenizer(test_texts, truncation=True, padding=True, return_tensors=\"pt\")\n",
        "test_dataset = torch.utils.data.TensorDataset(\n",
        "    test_encodings[\"input_ids\"],\n",
        "    test_encodings[\"attention_mask\"],\n",
        ")\n",
        "\n",
        "# Use the trained model to make predictions on the test set\n",
        "model.eval()\n",
        "predictions = []\n",
        "for batch in torch.utils.data.DataLoader(test_dataset, batch_size=8):\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    with torch.no_grad():\n",
        "        inputs = {\"input_ids\": batch[0], \"attention_mask\": batch[1]}\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.logits\n",
        "        batch_predictions = torch.argmax(logits, axis=1)\n",
        "        predictions.extend(batch_predictions.detach().cpu().numpy().tolist())\n",
        "\n",
        "# Add the predicted labels to the test data DataFrame\n",
        "test_data[\"predicted_label\"] = predictions\n",
        "\n",
        "# Save the labeled dataset to a CSV file\n",
        "test_data.to_csv(\"/content/drive/MyDrive/Colab Notebooks/tlg_labeled_predictions.csv\", index=False)\n",
        "print(\"Labeled dataset saved to tlg_labeled_predictions.csv\")\n",
        "\n",
        "# Print the Text and the predicted label of each example in the test set\n",
        "for i, text in enumerate(test_texts):\n",
        "    label = predictions[i]\n",
        "    print(f\"{text}\\n{label}\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f8a38746",
      "metadata": {
        "id": "f8a38746"
      },
      "outputs": [],
      "source": [
        "for name, param in model.named_parameters():\n",
        "    print(f\"Parameter name: {name}\")\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3972e84a",
      "metadata": {
        "id": "3972e84a"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "687528ce5f9643eb84a795ab7e005392": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d8f0cfeb34c44a468c150429b8e023c3",
              "IPY_MODEL_23909718ef834e2292564f32431d10f1",
              "IPY_MODEL_c1db9c843f2d4dbb8fc5feab7335f8cc"
            ],
            "layout": "IPY_MODEL_daa52294c43b493d8f7119edf1e83bf3"
          }
        },
        "d8f0cfeb34c44a468c150429b8e023c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_23ab5068b0274683a5883d0b6676bf93",
            "placeholder": "​",
            "style": "IPY_MODEL_056cd416375943e88b1f8c78a2399664",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "23909718ef834e2292564f32431d10f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_059d9aa3ac7540a7b487eee1917eb947",
            "max": 385,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_778075f30d6b47e080f20f6d46869d2b",
            "value": 385
          }
        },
        "c1db9c843f2d4dbb8fc5feab7335f8cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_19207e95730d47ab8b6cbf25c96e0f9c",
            "placeholder": "​",
            "style": "IPY_MODEL_775e1406b9a44c0a9b8b9b5cc5d113db",
            "value": " 385/385 [00:00&lt;00:00, 18.7kB/s]"
          }
        },
        "daa52294c43b493d8f7119edf1e83bf3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "23ab5068b0274683a5883d0b6676bf93": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "056cd416375943e88b1f8c78a2399664": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "059d9aa3ac7540a7b487eee1917eb947": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "778075f30d6b47e080f20f6d46869d2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "19207e95730d47ab8b6cbf25c96e0f9c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "775e1406b9a44c0a9b8b9b5cc5d113db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "223149698a794b789fb1bba04e0515fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2449de21a2034b90a74007bdb5c84bf2",
              "IPY_MODEL_915ddda5167848279eda36bcc13a5d3f",
              "IPY_MODEL_f9acecc92fb24c219e5436954692f7c1"
            ],
            "layout": "IPY_MODEL_1c823daf27e4412baf33a7f4d7d358c7"
          }
        },
        "2449de21a2034b90a74007bdb5c84bf2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f841b488a1aa4ea1b4ee6fe928de465f",
            "placeholder": "​",
            "style": "IPY_MODEL_39599b451cb246c0a5ff240458d17c6a",
            "value": "Downloading pytorch_model.bin: 100%"
          }
        },
        "915ddda5167848279eda36bcc13a5d3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_abe7010f42e046e893686503bac68659",
            "max": 445018508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d019e5f173ac4bc291d8cf8509d0685c",
            "value": 445018508
          }
        },
        "f9acecc92fb24c219e5436954692f7c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_137b5a1605bc42eab7e5522b1c2f4a2b",
            "placeholder": "​",
            "style": "IPY_MODEL_95e9e11836f34d03bad99730a64514a7",
            "value": " 445M/445M [00:01&lt;00:00, 290MB/s]"
          }
        },
        "1c823daf27e4412baf33a7f4d7d358c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f841b488a1aa4ea1b4ee6fe928de465f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "39599b451cb246c0a5ff240458d17c6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "abe7010f42e046e893686503bac68659": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d019e5f173ac4bc291d8cf8509d0685c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "137b5a1605bc42eab7e5522b1c2f4a2b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "95e9e11836f34d03bad99730a64514a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "61f077dc764b46f08228d7c9b87adf0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3d50a0b09a6d46f0b5bb04ddb449d713",
              "IPY_MODEL_d0e119ec3f324ef8b8f3d17f518e61a9",
              "IPY_MODEL_3dc68453879b40c18c37e7358a937d28"
            ],
            "layout": "IPY_MODEL_c5e0caa1cc774888b480edfbc4d9fdb9"
          }
        },
        "3d50a0b09a6d46f0b5bb04ddb449d713": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6c5ffb2c329b45a2a195e081645626ad",
            "placeholder": "​",
            "style": "IPY_MODEL_bc16acc4675541d49f4317c704bb74b5",
            "value": "Downloading (…)solve/main/vocab.txt: 100%"
          }
        },
        "d0e119ec3f324ef8b8f3d17f518e61a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_35841e629f284b9694870a33a5c748b9",
            "max": 251003,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1029b2dc2ca040b59263b391c19ad735",
            "value": 251003
          }
        },
        "3dc68453879b40c18c37e7358a937d28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0d3f9a8727b447a49263205d7eba15b0",
            "placeholder": "​",
            "style": "IPY_MODEL_3d31d53b120f48098ff12d1df8ba106b",
            "value": " 251k/251k [00:00&lt;00:00, 2.98MB/s]"
          }
        },
        "c5e0caa1cc774888b480edfbc4d9fdb9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c5ffb2c329b45a2a195e081645626ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc16acc4675541d49f4317c704bb74b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "35841e629f284b9694870a33a5c748b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1029b2dc2ca040b59263b391c19ad735": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0d3f9a8727b447a49263205d7eba15b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d31d53b120f48098ff12d1df8ba106b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "18ff91d71725447f9dd408ba2523243d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6a667352749749859ab47d0d29332a2e",
              "IPY_MODEL_cecae4a86587499f905e73782d7a3f3b",
              "IPY_MODEL_9625534697ae4ea4bb7ffdfebdb8fd75"
            ],
            "layout": "IPY_MODEL_fc6abb26ab3246a48e0918833572884d"
          }
        },
        "6a667352749749859ab47d0d29332a2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c87859f2c3bd4a79a91aba4356730438",
            "placeholder": "​",
            "style": "IPY_MODEL_ce95c60603ec4d418486503342091c54",
            "value": "Downloading (…)okenizer_config.json: 100%"
          }
        },
        "cecae4a86587499f905e73782d7a3f3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6b6bf22ce01f4e1a9325218a728d6fad",
            "max": 60,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b8737d03e85a452691edbabdca2959ba",
            "value": 60
          }
        },
        "9625534697ae4ea4bb7ffdfebdb8fd75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c4c050456efa48b2bea28804b31a1028",
            "placeholder": "​",
            "style": "IPY_MODEL_31eca2753ddd491594b85c757642a5c6",
            "value": " 60.0/60.0 [00:00&lt;00:00, 3.78kB/s]"
          }
        },
        "fc6abb26ab3246a48e0918833572884d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c87859f2c3bd4a79a91aba4356730438": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce95c60603ec4d418486503342091c54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6b6bf22ce01f4e1a9325218a728d6fad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b8737d03e85a452691edbabdca2959ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c4c050456efa48b2bea28804b31a1028": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "31eca2753ddd491594b85c757642a5c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}